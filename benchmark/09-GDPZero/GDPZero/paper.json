{
  "1": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 7101–7125\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nPrompt-Based Monte-Carlo Tree Search for\nGoal-oriented Dialogue Policy Planning\nXiao Yu, Maximillian Chen, Zhou Yu\nDepartment of Computer Science, Columbia University, New York, NY\n{xy2437, zy2461}@columbia.edu,\nmaxchen@cs.columbia.edu\nAbstract\nPlanning for goal-oriented dialogue often re-\nquires simulating future dialogue interactions\nand estimating task progress. Many approaches\nthus consider training neural networks to per-\nform look-ahead search algorithms such as A*\nsearch and Monte Carlo Tree Search (MCTS).\nHowever, this training often requires abundant\nannotated data, which creates challenges when\nfaced with noisy annotations or low-resource\nsettings.\nWe introduce GDP-ZERO, an ap-\nproach using Open-Loop MCTS to perform\ngoal-oriented dialogue policy planning with-\nout any model training. GDP-ZERO prompts\na large language model to act as a policy\nprior, value function, user simulator, and sys-\ntem model during the tree search. We evaluate\nGDP-ZERO on the goal-oriented task Persua-\nsionForGood, and find that its responses are\npreferred over ChatGPT up to 59.32% of the\ntime, and are rated more persuasive than Chat-\nGPT during interactive evaluations1.\n1\nIntroduction\nIn many goal-oriented conversation tasks, interact-\ning parties must retake initiative (Allen et al., 1999)\nby executing conversational strategies to lead the\nconversation a desired outcome (e.g. successful\nnegotiation (Lewis et al., 2017) or emotional sup-\nport (Liu et al., 2021)). As such, it is imperative to\nhave high-quality dialogue policy planners that can\nprescribe an “optimal” strategy at each turn of the\ndialogue (Levin et al., 1997; Zhang et al., 2020b;\nLiu and Lane, 2017; Liu et al., 2018).\nOptimal policy planning is a difficult task. While\nin task-oriented settings (e.g. restaurant booking)\nthere at least is objectivity with respect to success-\nful planning, many goal-oriented tasks like per-\nsuasion are often subjective. For instance, in a\npersuasion task, individual persuaders might adopt\ndifferent strategies, making it difficult to train or\n1Code available at: https://github.com/jasonyux/GDPZero\n     : If I'm in the right place at the right time or am given an\nopportunity. \n     [emotion appeal]: It's wonderful to see people like you who\ncare so much about helping others! It's important to support\ncauses that are close to our hearts. Children are ...\nPrediction\n     : Save the Children is a wonderful charity to donate to.\nWould you be interested in donating to the charity?\n: Do you ever donate to charities?\nprop. donate\nemotion appeal\nlogical appeal\nemotion\ncurrent\ndialogue\nlogical\nprop.\ntask. inquiry\nTurn\nv.s.\n1 MCTS Planning\nChatGPT\nGDP-Zero+ChatGPT\n2\n... some dialogue history\nagree to donate\ndisagree to donate\nFigure 1: Using GDP-ZERO for persuasion with zero\nmodel training.\nevaluate a policy planner2. Moreover, “optimal-\nity” in these complex tasks may require expert do-\nmain knowledge (e.g., negotiation skills). This\nalso makes collecting and annotating high-quality\nconversations difficult (Chen et al., 2023b).\nIn this work, we contribute a novel approach to\nGoal-oriented Dialogue Planning with Zero train-\ning (GDP-ZERO). GDP-ZERO prompts a large\nlanguage model (LLM) to perform planning by\nsimulating future dialogue interactions (Figure 1),\nmaking it particularly suitable for tasks which\nwould otherwise require high-quality conversations\n2In our extensive initial experiments to build a policy\nplanner for the PersuasionForGood (Wang et al., 2019) task,\nwe found 1) training a supervised or reinforcement learning-\nbased multi-class classifier for next-dialogue-act-prediction\nyields only 18-25% accuracy at best (including finetuning\nLLaMA (Touvron et al., 2023), RoBERTa (Liu et al., 2019),\nand prompting LLMs such as ChatGPT), and 2) converting the\nmulticlass policy prediction task into a binary task of whether\nto “propose to donate” still yields only 74% accuracy.\n7101\n",
  "2": "and annotations. Unlike previous approaches, we\ntreat policy planning as a stochastic game, and use\nprompting for every stage of an open-loop tree\nsearch. We evaluate GDP-ZERO on PersuasionFor-\nGood due to its difficult planning task (Wang et al.,\n2019), and find its responses are preferred over\nChatGPT in both static and interactive evaluations.\n2\nRelated Work\nPrompting Methods\nFew-shot dialogue tech-\nniques have a lot of advantages, including out-of-\ndomain generalization (Zhao and Eskenazi, 2018;\nMehri and Eskenazi, 2021) and difficult low re-\nsource settings with noisy annotations (Chen et al.,\n2023b). Recently, prompting LLMs has become\nthe predominant approach to few-shot language\ntasks, and its applications in dialogue have received\nmuch attention. However, this has largely focused\non dialogue response generation (e.g. Chen et al.\n(2023b); Liu and Kilicoglu (2023); Madotto et al.\n(2021); Liu et al. (2022)), conversation synthe-\nsis (e.g. Chen et al. (2023a); Kim et al. (2022);\nBae et al. (2022)), and dialogue understanding (e.g.\nYang et al. (2022); Gupta et al. (2022)). To date,\nprompting has not been used for policy planning.\nDialogue Policy Planning\nResearch on dialogue\npolicy planning can be categorized into neural-\nfocused and algorithmic-focused. Neural-focused\napproaches use annotated dialogues to train dedi-\ncated classifiers or value functions to predict the\nnext dialogue acts without explicit look-ahead plan-\nning (Zhang et al., 2022a,b; Cao et al., 2020;\nPeng et al., 2018; Zhang et al., 2023). For many\ngoal-oriented dialogues, however, both annotated\nstrategies and dialogue responses can be sub-\noptimal/noisy, as different people can respond dif-\nferently even given the same context.\nTo reduce the reliance on a labeled dataset, much\nwork has also attempted to combine neural net-\nworks with search algorithms, such as A* search\n(Cheng et al., 2022) and tree search (Wang et al.,\n2020; Yang et al., 2021; Jang et al., 2020; Väth\net al., 2023). However, these methods still require\nmodel training for dialogue simulation or value\nfunction estimation, and are therefore highly de-\npendent on training data quality (Shi et al., 2019).\nFor example, Jang et al. (2020) use MCTS for train-\ning an RNN-based policy model and Wang et al.\n(2020) train multiple neural networks for user simu-\nlation and value function estimation. Consequently,\nthese methods can face difficulties during dialogue\nsimulation due to a) noisy data annotations causing\nsub-optimally trained generation models, and b)\ninaccurate responses generated at turn i compound-\ning errors for simulations at turns > i.\n3\nMethod\nIn this work, we introduce GDP-ZERO, an\nalgorithm-focused dialogue policy planner for goal-\noriented dialogue tasks like persuasion.\nGDP-\nZERO uses zero model training and instead per-\nforms Open-Loop MCTS at decision time by\nprompting an LLM to simulate user and system\nresponse, evaluate current task progress, and pre-\ndict a prior next dialogue act. Building on find-\nings from Chen et al. (2023b), our approach has\ntwo main differences from existing policy planning\nwork: we use few-shot prompting to bypass the\nneed for model training on noisy data, and we use\nOpen-Loop MCTS to reduce compounding simu-\nlation errors by continuously re-generating system\nand user responses during the tree search.\n3.1\nProblem Definition\nTo introduce tree search methods for dialogue pol-\nicy planning, we first formulate planning as a\nMarkov Decision Process (MDP). A t turn dialogue\nbetween a user and a system can be represented as:\nh = (asys\n0 , usys\n1 , uusr\n1 , ..., asys\nt−1, usys\nt , uusr\nt\n)\nwhere asys\ni\nis the system’s dialogue act at turn\ni, usys\ni\nis the system’s response, and uusr\ni\nis the\nuser’s utterance at turn i. Similar to Yang et al.\n(2021) and Wang et al. (2020), we define the task\nof planning the next asys as an MDP problem\n⟨S, A, R, P, γ⟩. The dialogue act of the system\nasys\ni\nrepresents an action ai ∈A at a turn i, and the\ncorresponding dialogue history up to the i-th turn\nsi = (a0, usys\n1 , uusr\n1 , ..., ai−1, usys\ni\n, uusr\ni\n) represents\na state si ∈S. A reward function R(s, a) rep-\nresents the likelihood of a desired conversational\noutcome, such as persuading a user to donate to a\ncharity. The transition function P : S × A →S\nrepresents the probability of transitioning from a\ndialogue state si to state si+1 after executing ai at\na turn. Finally, γ ∈[0, 1) is the discount factor.\n3.2\nDialogue Planning as a Stochastic MDP\nIn a typical MDP game like Go, much success has\nbeen achieved by employing closed-loop MCTS to\nplan for the next move/action a (Silver et al., 2016,\n2017). In general, MCTS algorithms improve the\n7102\n",
  "3": "                                     Absolutely!\n... You can find reviews      ...\n credibility\nappeal\nroot\ngreeting\n....\n      ...history\n            Are you familiar with Save the Children?\n            No can you explain?\nlogical\nappeal\ngreeting\nemotional appeal\nlogical\nappeal\n ...history up to turn i\n       [credibility] .... reputable...        ....\n       [logical] Absolutely!      ....        Nice!       ....\nCache simulation and update tree\na\nb\nc\nExpansion and Evaluation\nBackpropagation\nSelection\nRepeat\nd\nPrediction\nroot\nBest DA next turn\ncredibility appeal\nIt's a very reputable organization ...\nBest Utt next turn\nwhen tree search (a)-(c) finished\n1\nestimate next action prob.\nlogical\nappeal\nPrompt [logical appeal]:\nroot\n...\n credibility\nappeal\n....\nsimulate next turn\nt=i\nsample from cache \nor simulate next turn\n[cred. appeal] It's a very reputable...\nInteresting ...\nt=i+2\nPrompt: Nice!      ...\n...history + simulation up to t=i+1\n: ...      ...\n: ...      ...\nt=i+2\nevaluate task progress\n2\nWould you like to make a donation?\nt=i+3\nx15\nPrompt: [emotional appeal]\nPrompt: [positive reaction]\nt=i+3\ndistribution\nx10\nt=i+1\naverage\n1\n2\n3\n4\nFigure 2: GDP-ZERO with ChatGPT backbone. During Selection, simulations are either sampled from cache or\nnewly generated. During Expansion and Evaluation, we prompt ChatGPT for prior policy π and value estimation.\nactions proposed by an original policy model πθ by\nbuilding a search tree that contain simulated out-\ncomes of many potentially high-rewarding actions,\nand returning the best action according to the sim-\nulation/evaluation results. Specifically, MCTS re-\npeatedly 1) explores a new action or exploits a suc-\ncessful action a proposed by πθ in a state s; 2) sim-\nulates the action outcome s′ ←P(s, a); 3) evalu-\nates the action’s quality; and 4) updates its estimate\nQ(s, a) for that action. At the end of the search,\nMCTS produces probabilities π ∝N(s, a)1/τ\nfor playing each action using the exponentiated\nvisit count, which usually suggests much stronger\nmoves than using the raw policy πθ (Howard, 1960;\nSutton and Barto, 2018; Silver et al., 2017).\nHowever, in simulating dialogue interactions\nduring tree search, generating a slightly improbable\nsystem or user response for state s′ and storing it\nin a search tree could lead to a large compounding\nerror for the rest of the subtree from s′ (Wang et al.\n(2020)). This is because the state space represent-\ning all possible responses is large, and dialogue\nresponses are diverse. This makes it difficult to\naccurately simulate the most probable next dia-\nlogue state s′ given an (s, a) pair from the previous\nturn. We thus treat dialogue policy planning as\na stochastic MDP, where the simulated next state\ns′ ←P(s, a) is drawn from a large unknown distri-\nbution and might not be representative of the most\nprobable s′ (Perez Liebana et al., 2015). Unlike pre-\nvious usages of (closed-loop) MCTS for dialogue\nwhich consider a deterministic transition (Wang\net al., 2020; Yang et al., 2021), this formulation re-\nquires potentially different s′ to be returned given\nthe same dialogue context s and system action a.\n3.3\nGDP-ZERO\nTo solve this stochastic problem, we base our\nalgorithm on Open-Loop MCTS (Weber, 2010;\nPerez Liebana et al., 2015), a variant of MCTS\nwhere each tree node str\ni = (a0, ..., ai) represents\nthe sequence of dialogue actions to reach a dia-\nlogue turn i. Instead of using system/user utter-\nances to represent a tree node, this design forces\nan algorithm to (re)generate the corresponding sys-\ntem and user utterances when traversing the tree\n(see Figure 2). Over time, a tree node str stores\nstatistics derived from executing the sequence of\ndialogue actions (DA) without relying on some\nspecific instance of user/system utterances, which\ncould cause errors to propagate into future simu-\nlations. Given a dialogue state s0, GDP-ZERO\nsearches for the next best action by iteratively per-\nforming action selection, search tree expansion,\naction evaluation, and backpropagation to update\ntree statistics. After n iterations, GDP-ZERO out-\nputs a prediction for the next best action for s0.\nGDP-ZERO is detailed in Figure 2 and Appendix A.\nBelow we describe each stage of the algorithm.\nSelection\nGiven a tree state str, the action a∗\nwith the highest Predictor Upper Confidence Tree\nBound (PUCT) (Silver et al., 2017; Rosin, 2011) is\nselected to traverse the tree:\nPUCT(str, a) = Q(str, a) + cp\npP\na N(str, a)\n1 + N(str, a) ,\n7103\n",
  "4": "where N records the number of times a (str, a)\npair has been visited, and cp is a hyperparameter\ncontrolling exploration. Since future simulations\nrequire a specific dialogue history, we either sample\nfrom the node’s simulation cache if its size reached\nk, or generate a new simulation based on selected\ndialogue history htr by prompting (Appendix B).\nWe repeat this process until str becomes leaf node.\nExpansion\nOnce a leaf node is reached, we treat\na LLM Mθ as a prior policy by prompting it to\ngenerate a distribution of next dialogue acts. This\nis done by sampling Mθ at temperature τ = 1.0\nfor m times, and converting the sampled DAs into\na distribution (see Appendix A). Finally, each DA\nis also initialized with Q(str, ·) = Q0, a hyperpa-\nrameter controlling exploration.\nEvaluation\nWe model the value of a state v(str)\nby the probability that its dialogue context htr\ncan lead to task success. In a persuasion task to\nconvince a user to donate to a charity, this can\nbe achieved by appending the utterance “Would\nyou like to make a donation?” to the context, and\nprompting an LLM l times to simulate the user’s\ncurrent inclination to donation (Appendix A).\nBackpropagation\nAt the end of each search, we\nfirst store any newly simulated histories htr in a\ncache for each str. Then, we update the statistics\nof all nodes along the search path:\nN(str, a) ←N(str, a) + 1\n(1)\nQ(str, a) ←Q(str, a) + ∆Q(str, a),\n(2)\nwhere ∆Q(str, a) = v(str)−Q(str,a)\nN(str,a)\n. We also store\na value vh estimated for each simulated history htr\nthat resulted in v(str) by a running average:\nvh(htr) ←vh(htr) × Nh(htr) + v(str)\nNh(htr) + 1\n,\n(3)\nwith Nh(·) stores the number of times htr is visited.\nPrediction\nAfter\nall\nsimulations\nare\ncom-\npleted, we select the optimal action a∗\n=\narg maxa N(str\n0 , a) based on the number of times\nan action has been visited, where str\n0 is the root\nnode of the tree. To avoid generating a response\nusing Mθ on a∗again, we also extract from cache\nthe best system utterance associated with executing\naction a∗at state str\n0 . We use vh computed during\nthe simulations, and return the utterance with the\nhighest estimated value:\nhtr\n∗= arg max\nhtr\na∗\nvh(htr\na∗),\nwhere htr\na∗denote any history htr that played action\na∗after the root state str\n0 . We call this process\n“response selection”.\n4\nExperiments\nWe evaluate GDP-ZERO in the context of Persua-\nsionForGood (P4G; Wang et al. (2019)), a dataset\nwith 300 annotated dialogues where a “persuader”\nattempts to persuade a “persuadee” to donate to\na charity called Save the Children (Appendix E).\nDue to the subjective nature of persuasion, it is not\nclear whether the annotated conversations reflect\noptimal persuasion strategies (Chen et al., 2022).\nThis makes training and evaluating a policy plan-\nner challenging, since different persuaders likely\nadopt different strategies (Section 1). Motivated by\nthis challenge, we employ GDP-ZERO to perform\ndecision-time planning based on dialogue simu-\nlations, and focus on evaluating our approach’s\nend-to-end performance in achieving the desired\ntask outcome: successfully persuading a user to\ndonate to Save the Children.\n4.1\nStatic Evaluation\nWe use ChatGPT3 (OpenAI, 2022) as the gen-\neration backbone of GDP-ZERO, which has be-\ncome accepted as one of the most coherent general-\npurpose LLM (e.g. Liu et al. (2023b); Guo et al.\n(2023)). We take the first 20 dialogues from P4G,\nand produce 154 turns for evaluation. For each turn,\nwe compare the response generated with and with-\nout GDP-ZERO for planning. Then, we prompted\nChatGPT to choose4 which generated response is\nmore persuasive (Appendix F).\nIn Table 1, we found that generative approaches\nusing ChatGPT were preferred over human ground\ntruth responses about 90% of the time, with the\nhighest score achieved by GDP-ZERO. In Table 2,\nwe show that responses generated after GDP-ZERO\nplanning were preferred in up to 59.32% of compar-\nisons. We also observe increasing preference for\nGDP-ZERO when the number of simulations n in-\ncreases. Finally, we find changing k, Q0 (controls\n3Version “gpt-3.5-turbo” as of 2023 April\n4ChatGPT can outperform crowdworkers on many annota-\ntion and evaluation tasks (e.g. Gilardi et al. (2023); He et al.\n(2023); Pan et al. (2023); Wang et al. (2021); Liu et al. (2023a))\n7104\n",
  "5": "Algorithm\nn\nk\nQ0\nWin Rate v. Ground Truth\nPrompting\n-\n-\n-\n88.84 ± 0.75%\nGDP-Zero\n5\n3\n0.00\n87.22 ± 0.61%\nGDP-Zero\n10\n3\n0.00\n90.69 ± 1.60%\nGDP-Zero\n20\n3\n0.00\n88.86 ± 1.24%\nGDP-Zero\n50\n3\n0.00\n89.82 ± 1.10%\nTable 1: Static evaluation with ChatGPT as backbone\nand judge. Results are µ ± σ repeated over three runs.\nGDP-Zero (ChatGPT)\nWin Rate v. ChatGPT\nn\nk\nQ0\nRun Time\n5\n3\n0.00\n18s\n50.65 ± 3.31%\n10\n3\n0.00\n36s\n50.86 ± 1.10%\n20\n3\n0.00\n75s\n53.24 ± 1.91%\n50\n3\n0.00\n740s\n59.32 ± 1.84%\n10\n1\n0.00\n16s\n49.57 ± 2.01%\n10\n2\n0.00\n29s\n51.30 ± 1.59%\n10\n3\n0.25\n36s\n57.79 ± 2.95%\n10\n3\n0.50\n36s\n53.03 ± 2.00%\nTable 2: Static evaluation ChatGPT as backbone and\njudge. Runner-up is colored in gray. Results are µ ± σ\nrepeated over three runs.\nsimulation diversity and exploration, respectively)\ncan slightly improve performance (Appendix A).\nHowever, we consider the possibility that a)\nChatGPT is biased towards its own generated dia-\nlogues (Liu et al., 2023a), and b) it might not have\na robust criteria of what constitutes persuasiveness.\nAs such, we also conducted interactive evaluation.\n4.2\nInteractive Human Evaluation\nWe conducted interactive human evaluation using\nthe LegoEval platform (Li et al., 2021) with crowd-\nworkers on Amazon Mechanical Turk. We primar-\nily sought to evaluate GDP-ZERO in an end-to-end\nchatbot against two competitive baselines. The\nfirst is prompting ChatGPT for generation without\nGDP-ZERO planning. The second follows Chen\net al. (2023b) by using ChatGPT with RAP (Chen\net al., 2022). To our knowledge, RAP is the cur-\nrent state-of-the-art system on P4G, using trained\nmodules with fixed dialogue policies derived from\nexpert knowledge. Recently, Chen et al. (2023b)\nshowed that using an LLM (e.g. ChatGPT) as the\nresponse generation module for RAP further im-\nproved performance (see Appendix G for details).\nAfter the conversation, we asked the crowdwork-\ners to evaluate our system based on the criteria\nin Table 3. We collected 40 survey results for\nGDP-ZERO, 35 for ChatGPT, and 36 for RAP\nThe chatbot...\nRAP\nChatGPT\nGDP-Zero\ndonation prob. ↑\n0.72±0.38\n0.73±0.38\n0.79±0.37\ninc. donation intent ↑\n4.08±0.68\n3.77±0.90\n4.30±0.71∗∗\nstrong argument ↑\n3.89±0.97\n3.91±0.99\n4.28±0.74∗\nis convincing ↑\n4.11±0.74\n4.10±0.70\n4.38±0.66∗∗\ndiverse strategy ↑\n3.98±0.80\n3.83±1.03\n3.95±0.82\nis manipulative ↓\n2.64±1.36\n2.96±1.38\n2.29±1.33∗∗\nis natural ↑\n4.25±0.68\n4.03±0.65\n4.38±0.62∗∗\nis relevant ↑\n4.64±0.54∗\n4.31±0.86\n4.59±0.49\nis coherent ↑\n4.28±0.65\n4.06±0.89\n4.42±0.49∗\nTable 3: Interactive evaluation using RAP, ChatGPT,\nand GDP-ZERO as planners, with ChatGPT used for\nresponse generation/backbone. Results are µ ± σ. All\nscores scaled to [1, 5] except for “donation prob.” being\n[0, 1]. ∗denotes p < 0.05, and ∗∗denotes p < 0.01.\n(Appendix H). Our study revealed that GDP-ZERO\nachieves the best performance across all metrics\nrelated to persuasiveness. We also found that RAP\nis highly rated for strategy diversity and relevance,\nindicating the benefit of using expert knowledge in\nplanning. In Appendix D we provide some anal-\nysis of the generated dialogues and the resulting\ndialogue act distributions using different planners.\nIn Appendix I we include some example dialogues.\n4.3\nAblation Studies\nTo study how various components of GDP-ZERO\nhelped improve task success, we conducted various\nablation studies including 1) using Closed-Loop\nMCTS instead of the open-loop variant; 2) remov-\ning the “response selection” process; and 3) testing\nwith both ChatGPT and Codex (Chen et al., 2021)\nas a backbone. Our experiments (see Appendix C)\nshow that using Open-Loop MCTS contributed the\nmost to making a response more persuasive, and\nthat using the “response selection” precedure fur-\nther improves performance. We also find that GDP-\nZERO can improve upon both backbone models.\n5\nConclusion\nWe propose GDP-ZERO, an algorithm to perform\nlook-ahead policy planning with a large language\nmodel for goal-oriented dialogues.\nEnd-to-end\nevaluation shows that using the policy from GDP-\nZERO surpasses previous state-of-the-art system\n(RAP) and direct prompting with state-of-the-art\nLLMs on the task of persuasion without any model\ntraining.\nStrong performance in the zero-data\nregime opens the possibility of future work build-\ning dialogue systems in more conversational tasks\nunder data-scarce settings.\n7105\n",
  "6": "6\nLimitations\nWhen is using GDP-ZERO appropriate?\nIn\nthis paper, we present GDP-ZERO, a general ap-\nproach for close-domain dialogue policy planning\nat turn-level. However, in this work we only eval-\nuated GDP-ZERO on P4G. This is because we\nbelieve simulation-based plannings would be most\nbeneficial when the task 1) often requires long-\nhorizon planning to be successful, 2) does not have\n“optimal” action annotations readily available for\nsupervised learning, and 3) evaluation does not re-\nquire study participants to follow fake hypothetical\nscenarios to conduct a conversation, as otherwise\nthe outcome may be disingenuous. We thus be-\nlieve tasks like persuasion are most suitable, where\nplanning ahead is crucial to success and policy op-\ntimality from human demonstrations is extremely\nsubjective. Additionally, such a user may or may\nnot want to donate to the charity, and the task of the\ndialogue system is to try to persuade them. This\nis in contrast to other goal-oriented contexts like\ntask-oriented dialogue (TOD), where strong poli-\ncies can be directly learned due to TOD’s mostly\npassive and objective nature (e.g. He et al. (2022)),\nand also to dialogues where a hypothetical scenario\nis required. For example, to design a fair and con-\ntrolled study, a user may need to make up fake\npreferences/objectives about a certain product in\nCraiglistsBargains (He et al., 2018), or pretend that\nthey need emotional support for some fixed set of\nissues in ESConv (Liu et al., 2021).\nAdditionally,\nwhile\nGDP-ZERO\ncan\nbe\nadapted to task-oriented contexts like Multi-\nWoz (Budzianowski et al., 2018), it may not\nnecessarily be appropriate.\nSuch task-oriented\ncontexts often have hierarchical policies (e.g.\n“[hotel] [recommend] name price” and “[restau-\nrant] [inform] food price area”), and adaptation\nto GDP-ZERO would require converting the\nhierarchy into a multi-label classification, resulting\nin a massive action space. We believe this could be\nvery inefficient, and approaches such as building\nmultiple search trees to perform high/low-level\nplanning would be useful (Zhang et al., 2020a).\nRuntime\nOne important limitation for GDP-\nZERO is runtime. The more exhaustive the tree\nsearch (e.g. increasing n or k), the more likely the\nalgorithm is able to find the optimal dialogue policy\n(Table 2). However, this comes at the cost of longer\nsimulation time, which may affect the overall user\nexperience, and accordingly, user perceptions of\npersuasiveness.\nWith OpenAI API’s rate limit and LLM’s in-\nference speed, we restricted GDP-ZERO to plan\non 7 dialogue acts in P4G, with n = 10, k = 3\nfor a simulation time of around 35 seconds during\ninteractive evaluation. We believe methods to paral-\nlelize tree search (Chaslot et al., 2008) or to re-use\npart of the simulation subtrees could be helpful to\nspeed up GDP-ZERO. We expect that as research\nwith LLMs progresses, inference speed will con-\ntinue to improve. In the short-term, one may bypass\nlatency limitations by utilizing multiple accounts\nto parallelize API calls during simulation.\nSimulation Quality\nGDP-ZERO prompts a\nLLM (e.g. ChatGPT) to perform dialogue simula-\ntion and value estimation. Despite LLM’s strong\nfew-shot performance on many tasks, issues with\ncontrollable generation can still create errors during\nsimulation (e.g. generated system utterances might\nnot match planned dialogue action). GDP-ZERO\naccounts for such errors by using an Open-Loop\nsearch with k > 1, but this increases simulation\nruntime. We believe this trade-off between simula-\ntion quality and runtime is also an important aspect\nfor future work to consider.\nUsing ChatGPT for static analysis\nWhile Chat-\nGPT is shown to outperform crowdworkers on\nmany annotation and evaluation tasks (e.g. Gilardi\net al. (2023); He et al. (2023); Pan et al. (2023);\nWang et al. (2021); Liu et al. (2023a)), recent work\nhas been finding that LLMs like ChatGPT may\nfavor responses with a higher number of unique\ntokens (Wang et al., 2023). As such, we analyzed\nresponses between GDP-ZERO (n = 20, k =\n3, Q0 = 0) and ChatGPT, and found that there\nis indeed some positive correlation (r = 0.29,\np < 0.001) between the number of words in a\nresponse and ChatGPT’s preference for persuasive-\nness. However, it is not clear whether this is a\nlimitation in our setting. Our setting of evaluating\npersuasiveness is not quite the same as the typical\ncontext of considering direct preference; there are\nmany situations where longer responses which cor-\nrelate with persuasiveness (for instance, an aptly\nused logical appeal). As such, we conducted inter-\nactive evaluation with crowdworkers in Section 4.2\nand find that GDP-ZERO generated responses are\nindeed rated as more persuasive.\n7106\n",
  "7": "7\nEthical Considerations\nOur work describes an algorithm to perform dia-\nlogue policy planning for goal-oriented tasks with-\nout any model training. It is aimed at making future\ndialogue systems to build, and also better at helping\nusers/systems achieve their tasks/goals.\nPotential Abuses\nGenerally, while most algo-\nrithms are not designed for unethical usage, there\nis often potential for abuse in their applications. In\nour experiments with PersuasionForGood (Wang\net al., 2019), we apply GDP-ZERO on the goal of\nincreasing users’ intention to donate to a charity.\nHowever, because GDP-ZERO is fundamentally\ngoal-agnostic, it is possible to use them for unethi-\ncal tasks, such as scamming. We do not condone\nthe use of GDP-ZERO for any unlawful or morally\nunjust purposes.\nInteractive Human Evaluation\nIn this study,\nwe conducted interactive human evaluation using\ncrowdworkers on the Amazon Mechanical Turk\nplatform. All crowdworkers were informed that\nthey were speaking with a chatbot. All study par-\nticipants were paid at a rate of $15 per hour. Our\nstudy has received IRB approval.\nReferences\nJames E Allen, Curry I Guinn, and Eric Horvitz. 1999.\nMixed-initiative interaction. IEEE Intelligent Sys-\ntems and their Applications, 14(5):14–23.\nSanghwan Bae, Donghyun Kwak, Sungdong Kim,\nDonghoon Ham, Soyoung Kang, Sang-Woo Lee, and\nWoomyoung Park. 2022. Building a role specified\nopen-domain dialogue system leveraging large-scale\nlanguage models. In Proceedings of the 2022 Con-\nference of the North American Chapter of the Asso-\nciation for Computational Linguistics: Human Lan-\nguage Technologies, pages 2128–2150.\nPaweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang\nTseng, Iñigo Casanueva, Ultes Stefan, Ramadan Os-\nman, and Milica Gaši´c. 2018. Multiwoz - a large-\nscale multi-domain wizard-of-oz dataset for task-\noriented dialogue modelling. In Proceedings of the\n2018 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP).\nYan Cao, Keting Lu, Xiaoping Chen, and Shiqi Zhang.\n2020. Adaptive dialog policy learning with hind-\nsight and user modeling. In Proceedings of the 21th\nAnnual Meeting of the Special Interest Group on\nDiscourse and Dialogue, pages 329–338, 1st virtual\nmeeting. Association for Computational Linguistics.\nGuillaume MJ B Chaslot, Mark HM Winands, and\nH Jaap van Den Herik. 2008. Parallel monte-carlo\ntree search. In Computers and Games: 6th Interna-\ntional Conference, CG 2008, Beijing, China, Septem-\nber 29-October 1, 2008. Proceedings 6, pages 60–71.\nSpringer.\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming\nYuan, Henrique Ponde de Oliveira Pinto, Jared Ka-\nplan, Harri Edwards, Yuri Burda, Nicholas Joseph,\nGreg Brockman, Alex Ray, Raul Puri, Gretchen\nKrueger, Michael Petrov, Heidy Khlaaf, Girish Sas-\ntry, Pamela Mishkin, Brooke Chan, Scott Gray,\nNick Ryder, Mikhail Pavlov, Alethea Power, Lukasz\nKaiser, Mohammad Bavarian, Clemens Winter,\nPhilippe Tillet, Felipe Petroski Such, Dave Cum-\nmings, Matthias Plappert, Fotios Chantzis, Eliza-\nbeth Barnes, Ariel Herbert-Voss, William Hebgen\nGuss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie\nTang, Igor Babuschkin, Suchir Balaji, Shantanu Jain,\nWilliam Saunders, Christopher Hesse, Andrew N.\nCarr, Jan Leike, Josh Achiam, Vedant Misra, Evan\nMorikawa, Alec Radford, Matthew Knight, Miles\nBrundage, Mira Murati, Katie Mayer, Peter Welinder,\nBob McGrew, Dario Amodei, Sam McCandlish, Ilya\nSutskever, and Wojciech Zaremba. 2021. Evaluating\nlarge language models trained on code.\nMaximillian Chen, Alexandros Papangelis, Chenyang\nTao, Seokhwan Kim, Andy Rosenbaum, Yang Liu,\nZhou Yu, and Dilek Hakkani-Tur. 2023a. PLACES:\nPrompting language models for social conversation\nsynthesis. Findings of the Association for Computa-\ntional Linguistics: EACL 2023.\nMaximillian Chen, Weiyan Shi, Feifan Yan, Ryan Hou,\nJingwen Zhang, Saurav Sahay, and Zhou Yu. 2022.\nSeamlessly integrating factual information and social\ncontent with persuasive dialogue. In Proceedings of\nthe 2nd Conference of the Asia-Pacific Chapter of\nthe Association for Computational Linguistics and\nthe 12th International Joint Conference on Natural\nLanguage Processing, pages 399–413.\nMaximillian Chen, Xiao Yu, Weiyan Shi, Urvi Awasthi,\nand Zhou Yu. 2023b. Controllable mixed-initiative\ndialogue generation through prompting. In Proceed-\nings of the 61st Annual Meeting of the Association\nfor Computational Linguistics (Volume 2: Short Pa-\npers), pages 951–966, Toronto, Canada. Association\nfor Computational Linguistics.\nYi Cheng, Wenge Liu, Wenjie Li, Jiashuo Wang, Ruihui\nZhao, Bang Liu, Xiaodan Liang, and Yefeng Zheng.\n2022. Improving multi-turn emotional support dia-\nlogue generation with lookahead strategy planning.\nIn Proceedings of the 2022 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n3014–3026, Abu Dhabi, United Arab Emirates. As-\nsociation for Computational Linguistics.\nFabrizio Gilardi, Meysam Alizadeh, and Maël Kubli.\n2023. Chatgpt outperforms crowd-workers for text-\nannotation tasks.\n7107\n",
  "8": "Biyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang,\nJinran Nie, Yuxuan Ding, Jianwei Yue, and Yupeng\nWu. 2023. How close is chatgpt to human experts?\ncomparison corpus, evaluation, and detection.\nPrakhar Gupta, Cathy Jiao, Yi-Ting Yeh, Shikib Mehri,\nMaxine Eskenazi, and Jeffrey P Bigham. 2022. In-\nstructdial: Improving zero and few-shot generaliza-\ntion in dialogue through instruction tuning. EMNLP.\nHe He, Derek Chen, Anusha Balakrishnan, and Percy\nLiang. 2018. Decoupling strategy and generation in\nnegotiation dialogues.\nWanwei He, Yinpei Dai, Yinhe Zheng, Yuchuan Wu,\nZheng Cao, Dermot Liu, Peng Jiang, Min Yang, Fei\nHuang, Luo Si, et al. 2022. Galaxy: A generative\npre-trained model for task-oriented dialog with semi-\nsupervised learning and explicit policy injection. In\nProceedings of the AAAI Conference on Artificial\nIntelligence, volume 36, pages 10749–10757.\nXingwei He, Zhenghao Lin, Yeyun Gong, A Jin, Hang\nZhang, Chen Lin, Jian Jiao, Siu Ming Yiu, Nan Duan,\nWeizhu Chen, et al. 2023. Annollm: Making large\nlanguage models to be better crowdsourced annota-\ntors. arXiv preprint arXiv:2303.16854.\nRonald A Howard. 1960. Dynamic programming and\nmarkov processes.\nYoungsoo Jang, Jongmin Lee, and Kee-Eung Kim.\n2020.\nBayes-adaptive monte-carlo planning and\nlearning for goal-oriented dialogues. In Proceedings\nof the AAAI Conference on Artificial Intelligence,\nvolume 34, pages 7994–8001.\nHyunwoo Kim, Jack Hessel, Liwei Jiang, Ximing Lu,\nYoungjae Yu, Pei Zhou, Ronan Le Bras, Malihe\nAlikhani, Gunhee Kim, Maarten Sap, et al. 2022.\nSoda: Million-scale dialogue distillation with so-\ncial commonsense contextualization. arXiv preprint\narXiv:2212.10465.\nEsther Levin, Roberto Pieraccini, and Wieland Eck-\nert. 1997. Learning dialogue strategies within the\nmarkov decision process framework. In 1997 IEEE\nWorkshop on Automatic Speech Recognition and Un-\nderstanding Proceedings, pages 72–79. IEEE.\nMike Lewis, Denis Yarats, Yann Dauphin, Devi Parikh,\nand Dhruv Batra. 2017. Deal or no deal? end-to-end\nlearning of negotiation dialogues. In Conference on\nEmpirical Methods in Natural Language Processing.\nYu Li, Josh Arnold, Feifan Yan, Weiyan Shi, and Zhou\nYu. 2021. Legoeval: An open-source toolkit for dia-\nlogue system evaluation via crowdsourcing. In Pro-\nceedings of the 59th Annual Meeting of the Asso-\nciation for Computational Linguistics and the 11th\nInternational Joint Conference on Natural Language\nProcessing: System Demonstrations, pages 317–324.\nBing Liu and Ian Lane. 2017. Iterative policy learning\nin end-to-end trainable task-oriented neural dialog\nmodels. In 2017 IEEE Automatic Speech Recognition\nand Understanding Workshop (ASRU), pages 482–\n489. IEEE.\nBing Liu, Gökhan Tür, Dilek Hakkani-Tur, Pararth Shah,\nand Larry Heck. 2018. Dialogue learning with hu-\nman teaching and feedback in end-to-end trainable\ntask-oriented dialogue systems. In Proceedings of\nthe 2018 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 1 (Long Pa-\npers), pages 2060–2069.\nSiyang Liu, Chujie Zheng, Orianna Demasi, Sahand\nSabour, Yu Li, Zhou Yu, Yong Jiang, and Minlie\nHuang. 2021.\nTowards emotional support dialog\nsystems. In Proceedings of the 59th annual meeting\nof the Association for Computational Linguistics.\nYang Liu, Dan Iter, Yichong Xu, Shuohang Wang,\nRuochen Xu, and Chenguang Zhu. 2023a. Gpte-\nval: Nlg evaluation using gpt-4 with better human\nalignment. arXiv preprint arXiv:2303.16634.\nYiheng Liu, Tianle Han, Siyuan Ma, Jiayue Zhang,\nYuanyuan Yang, Jiaming Tian, Hao He, Antong Li,\nMengshen He, Zhengliang Liu, Zihao Wu, Dajiang\nZhu, Xiang Li, Ning Qiang, Dingang Shen, Tianming\nLiu, and Bao Ge. 2023b. Summary of chatgpt/gpt-4\nresearch and perspective towards the future of large\nlanguage models.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach.\nYiren Liu and Halil Kilicoglu. 2023. Commonsense-\naware prompting for controllable empathetic dia-\nlogue generation. arXiv preprint arXiv:2302.01441.\nZihan Liu, Mostofa Patwary, Ryan Prenger, Shrimai\nPrabhumoye, Wei Ping, Mohammad Shoeybi, and\nBryan Catanzaro. 2022. Multi-stage prompting for\nknowledgeable dialogue generation. In Findings of\nthe Association for Computational Linguistics: ACL\n2022, pages 1317–1337.\nAndrea Madotto, Zhaojiang Lin, Genta Indra Winata,\nand Pascale Fung. 2021.\nFew-shot bot: Prompt-\nbased learning for dialogue systems. arXiv preprint\narXiv:2110.08118.\nShikib Mehri and Maxine Eskenazi. 2021. Schema-\nguided paradigm for zero-shot dialog. In Proceed-\nings of the 22nd Annual Meeting of the Special In-\nterest Group on Discourse and Dialogue, pages 499–\n508, Singapore and Online. Association for Compu-\ntational Linguistics.\nOpenAI. 2022. Openai: Introducing chatgpt.\nAlexander Pan, Chan Jun Shern, Andy Zou, Nathaniel\nLi, Steven Basart, Thomas Woodside, Jonathan Ng,\nHanlin Zhang, Scott Emmons, and Dan Hendrycks.\n7108\n",
  "9": "2023. Do the rewards justify the means? measur-\ning trade-offs between rewards and ethical behav-\nior in the machiavelli benchmark. arXiv preprint\narXiv:2304.03279.\nBaolin Peng, Xiujun Li, Jianfeng Gao, Jingjing Liu, and\nKam-Fai Wong. 2018. Deep Dyna-Q: Integrating\nplanning for task-completion dialogue policy learn-\ning. In Proceedings of the 56th Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers), pages 2182–2192, Melbourne,\nAustralia. Association for Computational Linguistics.\nDiego Perez Liebana, Jens Dieskau, Martin Hunermund,\nSanaz Mostaghim, and Simon Lucas. 2015. Open\nloop search for general video game playing. In Pro-\nceedings of the 2015 Annual Conference on Genetic\nand Evolutionary Computation, GECCO ’15, page\n337–344, New York, NY, USA. Association for Com-\nputing Machinery.\nChristopher D Rosin. 2011. Multi-armed bandits with\nepisode context. Annals of Mathematics and Artifi-\ncial Intelligence, 61(3):203–230.\nWeiyan Shi, Kun Qian, Xuewei Wang, and Zhou Yu.\n2019. How to build user simulators to train RL-based\ndialog systems. In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP),\npages 1990–2000, Hong Kong, China. Association\nfor Computational Linguistics.\nDavid Silver, Aja Huang, Chris J. Maddison, Arthur\nGuez, Laurent Sifre, George van den Driessche, Ju-\nlian Schrittwieser, Ioannis Antonoglou, Veda Pan-\nneershelvam, Marc Lanctot, Sander Dieleman, Do-\nminik Grewe, John Nham, Nal Kalchbrenner, Ilya\nSutskever, Timothy Lillicrap, Madeleine Leach, Ko-\nray Kavukcuoglu, Thore Graepel, and Demis Hass-\nabis. 2016. Mastering the game of go with deep neu-\nral networks and tree search. Nature, 529(7587):484–\n489.\nDavid Silver, Julian Schrittwieser, Karen Simonyan,\nIoannis Antonoglou, Aja Huang, Arthur Guez,\nThomas Hubert, Lucas Baker, Matthew Lai, Adrian\nBolton, Yutian Chen, Timothy Lillicrap, Fan Hui,\nLaurent Sifre, George van den Driessche, Thore\nGraepel, and Demis Hassabis. 2017. Mastering the\ngame of Go without human knowledge.\nNature,\n550(7676):354–359.\nRichard S Sutton and Andrew G Barto. 2018. Reinforce-\nment learning: An introduction. MIT press.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal\nAzhar, Aurelien Rodriguez, Armand Joulin, Edouard\nGrave, and Guillaume Lample. 2023. Llama: Open\nand efficient foundation language models.\nDirk Väth, Lindsey Vanderlyn, and Ngoc Thang Vu.\n2023. Conversational tree search: A new hybrid di-\nalog task. In Proceedings of the 17th Conference of\nthe European Chapter of the Association for Compu-\ntational Linguistics, pages 1264–1280, Dubrovnik,\nCroatia. Association for Computational Linguistics.\nShuohang Wang, Yang Liu, Yichong Xu, Chenguang\nZhu, and Michael Zeng. 2021.\nWant to reduce\nlabeling cost?\ngpt-3 can help.\narXiv preprint\narXiv:2108.13487.\nSihan Wang, Kaijie Zhou, Kunfeng Lai, and Jianping\nShen. 2020. Task-completion dialogue policy learn-\ning via Monte Carlo tree search with dueling network.\nIn Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 3461–3471, Online. Association for Computa-\ntional Linguistics.\nXuewei Wang, Weiyan Shi, Richard Kim, Yoojung Oh,\nSijia Yang, Jingwen Zhang, and Zhou Yu. 2019. Per-\nsuasion for good: Towards a personalized persuasive\ndialogue system for social good. In Proceedings of\nthe 57th Annual Meeting of the Association for Com-\nputational Linguistics, pages 5635–5649, Florence,\nItaly. Association for Computational Linguistics.\nYizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack\nHessel, Tushar Khot, Khyathi Raghavi Chandu,\nDavid Wadden, Kelsey MacMillan, Noah A. Smith,\nIz Beltagy, and Hannaneh Hajishirzi. 2023. How\nfar can camels go? exploring the state of instruction\ntuning on open resources.\nRichard Weber. 2010. Optimization and control. Uni-\nversity of Cambridge.\nJingxuan Yang, Si Li, and Jun Guo. 2021. Multi-turn\ntarget-guided topic prediction with Monte Carlo tree\nsearch. In Proceedings of the 18th International Con-\nference on Natural Language Processing (ICON),\npages 324–334, National Institute of Technology\nSilchar, Silchar, India. NLP Association of India (NL-\nPAI).\nYuting Yang, Wenqiang Lei, Juan Cao, Jintao Li,\nand Tat-Seng Chua. 2022.\nPrompt learning for\nfew-shot dialogue state tracking.\narXiv preprint\narXiv:2201.05780.\nCong Zhang, Huilin Jin, Jienan Chen, Jinkuan Zhu,\nand Jinting Luo. 2020a. A hierarchy mcts algorithm\nfor the automated pcb routing. In 2020 IEEE 16th\nInternational Conference on Control & Automation\n(ICCA), pages 1366–1371.\nHaodi Zhang, Zhichao Zeng, Keting Lu, Kaishun Wu,\nand Shiqi Zhang. 2022a. Efficient dialog policy learn-\ning by reasoning with contextual knowledge. In Pro-\nceedings of the AAAI Conference on Artificial Intelli-\ngence, volume 36, pages 11667–11675.\nQiang Zhang, Jason Naradowsky, and Yusuke Miyao.\n2023. Ask an expert: Leveraging language models to\nimprove strategic reasoning in goal-oriented dialogue\nmodels.\n7109\n",
  "10": "Shuo Zhang, Junzhou Zhao, Pinghui Wang, Yu Li,\nYi Huang, and Junlan Feng. 2022b. \" think before\nyou speak\": Improving multi-action dialog policy\nby planning single-action dialogs. arXiv preprint\narXiv:2204.11481.\nZheng Zhang, Lizi Liao, Xiaoyan Zhu, Tat-Seng Chua,\nZitao Liu, Yan Huang, and Minlie Huang. 2020b.\nLearning goal-oriented dialogue policy with opposite\nagent awareness. In Proceedings of the 1st Confer-\nence of the Asia-Pacific Chapter of the Association\nfor Computational Linguistics and the 10th Interna-\ntional Joint Conference on Natural Language Pro-\ncessing, pages 122–132.\nTiancheng Zhao and Maxine Eskenazi. 2018. Zero-shot\ndialog generation with cross-domain latent actions.\nIn Proceedings of the 19th Annual SIGdial Meeting\non Discourse and Dialogue, pages 1–10.\n7110\n",
  "11": "A\nAdditional details on GDP-ZERO\nWe describe the details of GDP-ZERO in Al-\ngorithm 1. Similar to other MCTS algorithms,\nGDP-ZERO performs simulation based on four\nstages, selection, expansion, evaluation, and back-\npropagation, and finally predicts an action based on\nthe simulations. Different from existing implemen-\ntations, GDP-ZERO performs Open-Loop search\nusing only a generative LLM Mθ, by prompting it\nto do dialogue simulation, value function estima-\ntion, and prior policy estimation (see Appendix B\nfor prompting details and examples).\nGDP-ZERO requires a generative LLM Mθ as\na backbone model, and takes in a dialogue history\nhi at turn i as input. Given some fixed dialogue\naction space A (see appendix E for P4G), GDP-\nZERO builds a search tree after n simulations. For\neach state, GDP-ZERO keeps a cache of size k\nstoring newly generated user and system utterances.\nWe use cp = 1.0, and Q0 = {0.0, 0.25, 0.5} to\npromote exploration (see Table 2).\nB\nPrompting Details on P4G\nFor P4G, we used the same one-shot example for\nall cases, while dynamically changing the represen-\ntation for each operation.\nSystem response generation.\nFollowing Chen\net al. (2023b), we include the natural language\nform of a planned dialogue action (Table A4) in\nthe prompt to perform conditional generation. We\npresent an example in Table A7.\nUser response generation.\nWe swap the user and\nthe system role for this task, and prompt the LLM\nto act as a user simulator. We present an example\nin Table A8.\nValue function estimation.\nTo evaluate the\nuser’s inclination to donate at a given state, we\nfirst append the turn “Persuader: Would you be\ninterested in donating to Save the Children?” to\nthe dialogue history, and then prompt the LLM at\ntemperature τ = 1.1 to sample the user’s response\nfor l = 10 times. We define “no donation”=-1.0,\n“negative reaction”=-0.5, “neutral”=0.0, “positive\nreaction”=0.5, and “donation”=1.0, and then con-\nvert the sampled responses to a score between -1.0\nand 1.0. We present an example in Table A9.\nPrior policy estimation.\nWe treat the backbone\nLLM as a prior policy, and prompt it to generate the\nnext dialogue action at temperature τ = 1.0 for 15\ntimes to simulate its policy distribution. Finally, to\npromote the diversity of the generated dialogue ac-\ntions during GDP-ZERO tree search, we use add-1\nsmoothing to convert the generated dialogue ac-\ntions to a probability distribution. We present an\nexample in Table A10.\nAlgorithm 1 GDP-Zero (Mθ)\nRequire: generative LLM Mθ\nRequire: dialogue history hi until turn i\nRequire: dialogue action space a ∈A\nRequire: hyperparameter n, k, cp, Q0\n1: Repeat for n searches:\n2: initialize root node str\ni , H(str\ni ) ←{hi}\n3: str ←str\ni\n4: // selection\n5: while str is not a leaf node do\n6:\na′ ←arg maxa PUCT(str, a; cp)\n7:\nhtr ←sample(H(str))\n8:\nstr ←str ∪a′\n9:\nif len(H(str)) < k then\n10:\ngenerate hnew ←Mθ(htr ◦a′)\n11:\nsave H(str) ←H(str) ∪hnew\n12:\nend if\n13: end while\n14: htr ←sample(H(str))\n15: // expansion\n16: generate p(a|str) ←Mθ(htr)\n17: str.p ←p(a|str), str.Q ←Q0, str.N = 0\n18: // evaluation\n19: generate v(str) ←Mθ(htr)\n20: // backpropagation\n21: while str ̸= str\ni do\n22:\nupdate vh(htr) with eq. (3)\n23:\nsave simulation H(str) ←H(str) ∪htr\n24:\n(str, a) ←back to parent of str\n25:\nupdate Q(str, a), N(str, a) with eq. (1)\n26: end while\n27: // prediction after n simulations\n28: a∗←arg maxa N(str\ni , a)\n29: str\n∗←str\ni ∪a∗\n30: usys∗←arg maxusys vh(H(str\n∗))\n31: return a∗, usys∗\nC\nAblation Studies\nIn Table A1 and Table A2, we conduct ablations to\nstudy how each component in GDP-ZERO affect\nits performance. We use the same 20 dialogues\nfrom our static evaluation (Section 4.1), and test\n7111\n",
  "12": "credibility\nemotion\ngreeting\nlogical\nother\nprop. donate\ntask inquiry\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\nFrequency / Turn\nGDP-Zero\nChatGPT\nRAP\n(a) During turn 1-2\ncredibility\nemotion\ngreeting\nlogical\nother\nprop. donate\ntask inquiry\n0.0\n0.1\n0.2\n0.3\nFrequency / Turn\nGDP-Zero\nChatGPT\nRAP\n(b) During turn 3-5\ncredibility\nemotion\ngreeting\nlogical\nother\nprop. donate\ntask inquiry\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\nFrequency / Turn\nGDP-Zero\nChatGPT\nRAP\n(c) During turn 6-10\ncredibility\nemotion\ngreeting\nlogical\nother\nprop. donate\ntask inquiry\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\nFrequency / Turn\nGDP-Zero\nChatGPT\nRAP\n(d) Overall\nFigure A1: Distribution of planned dialogue actions for each planner during interactive evaluations.\nGDP-Zero with ChatGPT (Table A2) and Codex5\n(Table A1) as the generation backbone. Similar\nto Section 4.1, we use ChatGPT to evaluate the\npersuasiveness of the generated responses.\nIn all runs, we use n = 20, cp = 1, Q0 = 0, k =\n3 for GDP-ZERO, when applicable.\nTable A1\nand Table A2 shows that GDP-ZERO improves\nthe policy proposed by the raw backbone model,\nand also that of a Closed-Loop MCTS implemen-\ntation (denoted as “w/o OpenLoop”) and without\nthe “response selection” process (denoted as “w/o\nResp.Select”). This indicates that using the open-\nloop variant and the proposed “response selection”\nprocess are beneficial for GDP-ZERO to improve\ndialogue planning.\nD\nAnalysis of GDP-ZERO Dialogues\nIn our experiments, we utilized GDP-ZERO to gen-\nerate persuasive responses to convince a persuadee\nto donate to a charity. In this section, we provide\nan analysis of how and when GDP-ZERO impacts\npersuasiveness.\n5At the time of writing, Codex (Chen et al., 2021) was\nfreely accessible from the OpenAI API.\nAlgorithm\nBackbone\nWin Rate v. GT\nPrompting\nCodex\n38.09 ± 2.00%\nGDP-Zero\nCodex\n45.46 ± 2.95%\nw/o OpenLoop\nCodex\n39.16± 3.42%\nw/o Resp.Select\nCodex\n40.80± 1.47%\nTable A1: Static evaluation using the first 20 dialogues\nof P4G with ChatGPT as judge. GT refers to Ground\nTruth. Results are µ ± σ repeated over three runs.\nAlgorithm\nBackbone\nWin Rate v. GT\nPrompting\nChatGPT\n87.21 ± 0.60%\nGDP-Zero\nChatGPT\n91.13 ± 0.30%\nw/o OpenLoop\nChatGPT\n88.09± 0.81%\nw/o Resp.Select\nChatGPT\n91.03± 0.75%\nTable A2: Static evaluation using the first 20 dialogues\nof P4G with ChatGPT as judge. GT refers to Ground\nTruth. Results are µ ± σ repeated over three runs. Since\nChatGPT generations are typically long, we use the first\n3 sentences of each generation in this evaluation.\nStatic evaluation.\nOur static evaluation (Sec-\ntion 4.1) uses fixed dialogue contexts from the P4G\ndataset (Wang et al., 2019), and every turn of the\nconversation is already annotated with dialogue\n7112\n",
  "13": "actions. We thus utilize those annotations and in-\nvestigate when GDP-ZERO is producing more per-\nsuasive responses. For this analysis GDP-ZERO\nused n = 10, k = 3, Q0 = 0.25, which is the\nsame configuration as in our interactive evalua-\ntion (Section 4.2, Appendix G). We found that\nGDP-ZERO is rated as more persuasive 70.59%\nof the time when the user at the previous turn\nshowed negative emotions (i.e. \"negative-reaction-\nto-donation\" or \"negative-to-inquiry\"), and 59.26%\nof the time when the user showed positive emotions\n(i.e. \"positive-reaction-to-donation\" and \"positive-\nto-inquiry\"). We believe this implies that GDP-\nZERO’s simulations are most beneficial in persuad-\ning users who is having little intent to donation.\nThis is because look-ahead planning may, for in-\nstance, help ensure a response has covered all of\nthe user’s concerns regarding donation. We present\nan example in Table A6.\nInteractive evaluation.\nSince each interactive\ndialogue is unlabeled, here we focus on analyz-\ning the known dialogue actions generated by the\ndifferent planners during those conversations. In\nFigure A1 we present the distribution of planned\ndialogue actions produced by RAP, ChatGPT, and\nGDP-ZERO. In general, the planned dialogue ac-\ntions using ChatGPT and GDP-ZERO are unevenly\ndistributed across different stages of the dialogue.\nAcross different times of the conversation, Chat-\nGPT and GDP-ZERO shared the most frequent\nDA at each stage is: “greeting” during turns 1-2,\n“logical appeal” during turns 3-5, and “emotion\nappeal” during turn 6-10. However, during turns\n3-5 GDP-ZERO had a relatively even preference\nbetween “credibility appeal”, “emotion appeal”,\nand “logical appeal”, while ChatGPT strongly pre-\nferred “logical appeal.” Additionally, we find that\nthroughout all turns ChatGPT prefers to use “emo-\ntion appeal” over other dialogue actions, while\nGDP-ZERO balances between “emotion appeal”\nand “logical appeal,” and RAP prefers “task related\ninquiry.” It is also worth noting that GDP-ZERO\nperforms “proposition of donation” less frequently\nat turn 1-5 than ChatGPT, and more frequently at\nturns 6-10. This indicates GDP-ZERO potentially\nadopting a more “conservative” strategy than Chat-\nGPT overall. GDP-ZERO focuses on building up\npersuasive arguments and is less likely to select\n“proposition of donation” at early stages of the con-\nversation in order to avoid over eargly propositions,\nwhich could lead to persuasion failure (also see\nTable A12).\nE\nGDP-ZERO Setup on P4G\nPersuasionForGood (P4G) is annotated with 10 per-\nsuasion strategies and 7 important non-persuasive\nstrategies (see Table A3). However, since P4G\nis collected from human-human interaction, with\nboth the “persuader“ and the “persuadee“ possi-\nbly donating to the charity, some of the dialogue\nactions are unsuitable when the “persuader“ is a\nchatbot (e.g. self-modeling and personal story).\nWe therefore choose a subset of dialogue actions\nto plan, by picking 4 frequent persuasive strategies\nsuitable for chatbots, and 3 non-persuasive strate-\ngies including “other“ to enable the chatbot to deal\nwith unaccounted situations. We present the cho-\nsen dialogue actions and their prompts for LLM in\nTable A4.\nDialogue Act\nCategory\nAmount\nLogical appeal\nStrategy\n325\nEmotion appeal\nStrategy\n237\nCredibility appeal\nStrategy\n779\nFoot-in-the-door\nStrategy\n134\nSelf-modeling\nStrategy\n150\nPersonal story\nStrategy\n91\nDonation information\nStrategy\n362\nSource-related inquiry\nStrategy\n167\nTask-related inquiry\nStrategy\n180\nPersonal-related inquiry\nStrategy\n151\nGreeting\nNon-Strategy\n-\nProposition of donation\nNon-Strategy\n-\nProposition of amount\nNon-Strategy\n-\nProposition of confirmation\nNon-Strategy\n-\nProposition of more donat.\nNon-Strategy\n-\nExperience affirmation\nNon-Strategy\n-\nThank\nNon-Strategy\n-\nTable A3: Annotated dialogue actions in the P4G\ndataset.\nF\nAdditional details on static evaluation\nIn our static evaluation, we prompt ChatGPT to\nchoose which generated response is better (e.g.\nwith and without GDP-ZERO planning). Given\ntwo responses ua and ub, we ask ChatGPT “Which\nof the following responses can better help the Per-\nsuader convince the Persuadee to donate to Save\nthe Children? Why? A: ua, B: ub, C: Can’t tell.” af-\nter providing the relevant task context and dialogue\nhistory (see Table A5). For every evaluation, we\nsample the result 5 times and perform a majority\nvote. Interestingly, we find that ChatGPT skewed\ntowards choosing option A, preferred choosing A\n7113\n",
  "14": "Dialogue Act\nCategory\nNatural Language Form\nLogical Appeal\nStrategy\nThe Persuader use of reasoning and evidence to convince the Persuadee.\nEmotion Appeal\nStrategy\nThe Persuader uses an emotion appeal to convince the Persuadee.\nCredibility Appeal\nStrategy\nThe Persuader establishes credibility of Save the Children by citing its impact.\nTask Related Inquiry\nStrategy\nThe Persuader asks about the Persuadee’s knowledge or opinion related to\nSave the Children.\nProposition of Donation\nNon-Strategy\nThe Persuader asks if the Persuadee would like to make a small donation.\nGreeting\nNon-Strategy\nThe Persuader greets the Persuadee.\nOther\nNon-Strategy\nThe Persuader responds to the Persuadee without using any persuasive strategy.\nTable A4: Mapping of persuader dialogue actions to natural language prompts used for prompting LLMs.\nfor 95.45% when ua = ub. We therefore randomly\nswap option A and B during all of our evaluations.\nG\nAdditional details on interactive study\nIn our interactive evaluation, we compare the rule-\nbased planner from RAP, ChatGPT, and GDP-\nZERO in an end-to-end chatbot for the persuasion\ntask.\nRAP\nwe use the rule-based planner derived from\nexpert knowledge from RAP (Chen et al., 2022),\nwhich produces a dialogue action given a dialogue\ncontext. We then use the same prompting tem-\nplate in GDP-ZERO (Appendix B, Table A7), and\nprompt ChatGPT to produce a system response\nconditioned on the planned dialogue action.\nChatGPT\nwe first use the same prompting tem-\nplate in GDP-ZERO (Appendix B, Table A10) to\nobtain ChatGPT’s own prior distribution of the next\ndialogue actions. We then take the most probable\naction as the planned dialogue action, and use the\nsame template in GDP-ZERO (Appendix B, Ta-\nble A7) to prompt ChatGPT again to produce a\nsystem response.\nGDP-ZERO\nwe use GDP-ZERO with ChatGPT\nbackbone as policy planner, and use the \"Response\nSelection\" step to produce both the next dialogue\naction and the associated system response. We used\nn = 10, k = 3, Q0 = 0.25, which had a high win\nrate against ChatGPT during static analysis while\nalso not taking too much time to simulate.\nH\nAdditional details on survey results\nWe require our crowdworkers to be located in the\nUnited States and have a HIT acceptance rate of\nat least 99%. After interacting with each chatbot,\neach crowdworker was asked to rate their conversa-\ntional experience. This post-task survey included a\nvalidation question which asked what charity they\ntalked to the chatbot about. We had a total of 216\nrespondents. 74 did not reach or complete the sur-\nvey, and 31 were removed due to failing the valida-\ntion question or responding with less than 3 unique\nsentences. This results in 40 survey results for\nGDP-ZERO, 35 for ChatGPT, and 36 for RAP.\nI\nExample Interactive Conversations\nWe present multiple dialogues from the interac-\ntive evaluation (Section 4.2), and compare the\nstrength and weaknesses of the three planners:\nRAP, ChatGPT, and GDP-ZERO. In Tables A11,\nA13 and A15 we present conversations where the\npersuadee “strongly agreed” that the chatbot has\nincreased his/her intention to donation for GDP-\nZERO, ChatGPT, and RAP, respectively. In Ta-\nbles A12, A14 and A16 we present conversations\nwhere the persuadee rated “neutral“ for the ques-\ntion that the chatbot has increased his/her intention\nto donation for GDP-ZERO, ChatGPT, and RAP,\nrespectively. We observe that in Table A12, while\nGDP-ZERO did not succeed in convincing the user\nto donate, GDP-ZERO has been attempting vari-\nous strategies and does not perform “proposition\nof donation” prematurely. On the other hand, in\nTables A14 and A16 both ChatGPT and RAP per-\nforms “proposition of donation” at an arguably un-\nsuitable timing.\n7114\n",
  "15": "Utterance\nPrompt\nThe following is background information about Save the Children.\nSave the Children is head-quartered in London, and they work to help fight poverty around the world.\nChildren need help in developing countries and war zones. Small donations like $1 or $2 go a long way\nto help.\nThe following is a conversation between a Persuader and a Persuadee about a charity called Save the\nChildren. The Persuader is trying to persuade the Persuadee to donate to Save the Children\n{insert dialogue context}\nWhich of the following responses can better help the Persuader convince the Persuadee to donate to\nSave the Children? Why?\nA. Persuader: {insert response a}\nB. Persuader: {insert response b}\nC. Can’t tell.\nYour can choose from either A, B, or C.\nYour choice:\nGeneration\nA. (rest truncated)\nTable A5: Prompting LLM to specify which generated response “response a” or “response b” is more persuasive.\nUtterance\nContext\nPersuader: Would you be interested in donating to Save the Children?\nPersuadee: I am one who like to donate. Can you tell me more about it?\nPersuader: Save the Children helps to promote childrens rights to health, education, and safety.\nPersuadee: Do they have any focus right now? More as where are the majority of the fund headed\ntowards right now\nPersuader: At this point a lot of the focus is children in war zones. some of these donations can address\nthe problem of the daily threat of violence\nPersuadee: It seems like Syria seems to be a high stakes area. Are any fund going to help the the\nchildren in Hawaii after the volcano and hurricane?\nPersuader: I’m not sure, but I think that would be a great idea. Maybe you could get more information\non that by getting in contact with someone at [URL]\nPersaudee: What are some of the things that they do for the children? I would like to donate but I am\nnot a huge fan or donating just for promotion?\nPersuader:\nCrowdworker\nThey help to provide basic health care, provide disaster relief, and help to ensure their rights to\neducation and safety. How much would you like to donate ? Your donation will be deducted from your\ntask payment.\nChatGPT\nSave the Children provides a variety of services to children in need, including education, healthcare,\nand protection from harm. They also work with communities to help them become more self-sufficient\nand better able to care for their children.\nGDP-ZERO\nSave the Children provides support in a variety of ways. They help create safe spaces for children,\nprovide education programs and materials, and offer medical care and support. They also advocate for\npolicy changes that benefit children’s rights around the world. Your donation would go directly to help\nthese programs rather than promotion.\nTable A6: Example response generated when using GDP-ZERO as the policy planner during static evaluation.\nCrowdworker’s response is the original response in the P4G dataset (Wang et al., 2019). GDP-ZERO used\nn = 10, k = 3, Q0 = 0.25 with ChatGPT as backbone.\n7115\n",
  "16": "Role (for ChatGPT)\nUtterance\nOne-shot Ex-\nample\nsystem\nSave the Children is head-quartered in London, and they work to help fight\npoverty around the world. Children need help in developing countries and\nwar zones. Small donations like $1 or $2 go a long way to help.\nYou are Persuader who is trying to persuade the Persuadee to donate to a\ncharity called Save the Children.\nThe following is an example conversation between a Persuader and a Per-\nsuadee.\nuser\nPersuadee: Hello. How are you?\nThe Persuader asks about the Persuadee’s knowledge or opinion related to\nSave the Children.\nassistant\nPersuader: Very well. I’m just up organizing info for my charity called Save\nthe Children. Have you heard of this charity before?\nuser\nPersuadee: No, I have not. Can you tell me more?\nThe Persuader establishes credibility of Save the Children by citing its impact.\nassistant\nPersuader: Save the Children is an organization that helps children in devel-\noping countries, by promoting children’s rights and providing relief. It is an\namazing charity that helps kids who are in desperate need. They can help\nwith safety, education and more.\nuser\nPersuadee: That sounds great. I believe in this charity, but still wonder how\nmuch of the money I donate actually helps. I am always worried if I donate it\nwill just go to some higher up that is living the high life.\nThe Persuader uses an emotion appeal to convince the Persuadee.\nassistant\nPersuader: Every little bit makes a difference. When you have people who\nare so poor, it’s amazing what a tiny amount can do. I usually donate in hopes\nI can at least feel like I did my part. If I donated and some corrupt person\ntook it, that’s the worst karma and even worst scandal imaginable\nuser\nPersuadee: With that all said I do feel like any organization that aims to help\nthe children I am more inclined to donate to them than most. I think helping\nchildren is an important thing as they are our future!\nThe Persuader asks if the Persuadee would like to make a small donation.\nassistant\nPersuader: I think donating to this cause would def be a step in the right\ndirection to hopefully helping across the world the children that are in despair.\nI don’t want you to donate any more than you want, so if you want to donate\nhow much do you to do?\nuser\nPersuadee: I would donate 1 dollar to this charity and feel good about it I\nthink.\nReal\ndia-\nlogue\nsystem\nThe following is a new conversation between Persuader (you) and a Persuadee.\nThe Persuader greets the persuadee.\nassistant\nPersuader: Hello. How are you?\nuser\nPersuadee: I am good. What about you?\nThe Persuader asks about the Persuadee’s knowledge or opinion related to\nSave the Children.\nassistant\nPersuader: I’m doing well, thanks for asking. I wanted to talk to you about\nan important cause that I am passionate about - Save the Children. Have you\nheard of them before?\nuser\nPersuadee: No I have not.\nThe Persuader establishes credibility of Save the Children by citing its impact.\nGeneration\nassistant\nSave the Children is an international non-governmental organization that is\ncommitted to improving the lives of children through education, healthcare,\nand other support programs. They work in over 100 countries around the\nworld to help children who are living in poverty or affected by conflict.\nTable A7: Prompting LLM to generate a system response conditioned on a dialogue act. “Role” is used to be\nconsistent with ChatGPT’s API. Blue texts are prompts characteristic of this task. The one-shot example changes its\nformatting across different tasks.\n7116\n",
  "17": "Role (for ChatGPT)\nUtterance\nOne-shot Ex-\nample\nsystem\nYou are a Persuadee. A Persuader is trying to persuade you to donate to a\ncharity called Save the Children.\nYou can choose amongst the following actions during a conversation to\nrespond to the Persuader:\n[no donation] [negative reaction] [neutral] [positive reaction] [donate].\nThe following is an example conversation between a Persuader and some\nPersuadee.\nassistant\nPersuadee: [neutral] Hello. How are you?\nuser\nPersuader: Very well. I’m just up organizing info for my charity called Save\nthe Children. Have you heard of this charity before?\nassistant\nPersuadee: [neutral] No, I have not. Can you tell me more?\nuser\nPersuader: Save the Children is an organization that helps children in devel-\noping countries, by promoting children’s rights and providing relief. It is an\namazing charity that helps kids who are in desperate need. They can help\nwith safety, education and more.\nassistant\nPersuadee: [negative reaction] That sounds great. I believe in this charity, but\nstill wonder how much of the money I donate actually helps. I am always\nworried if I donate it will just go to some higher up that is living the high life.\nuser\nPersuader: Every little bit makes a difference. When you have people who\nare so poor, it’s amazing what a tiny amount can do. I usually donate in hopes\nI can at least feel like I did my part. If I donated and some corrupt person\ntook it, that’s the worst karma and even worst scandal imaginable\nassistant\nPersuadee: [positive reaction] With that all said I do feel like any organization\nthat aims to help the children I am more inclined to donate to them than most.\nI think helping children is an important thing as they are our future!\nuser\nPersuader: I think donating to this cause would def be a step in the right\ndirection to hopefully helping across the world the children that are in despair.\nI don’t want you to donate any more than you want, so if you want to donate\nhow much do you to do?\nassistant\nPersuadee: [donate] I would donate 1 dollar to this charity and feel good\nabout it I think.\nReal\ndia-\nlogue\nsystem\nThe following is a new conversation between a Persuader and a Persuadee\n(you). You may or may not want to donate to Save the Children.\nuser\nPersuader: Hello. How are you?\nassistant\nPersuadee: [neutral] I am good. What about you?\nuser\nPersuader: I’m doing well, thanks for asking. I wanted to talk to you about\nan important cause that I am passionate about - Save the Children. Have you\nheard of them before?\nassistant\nPersuadee: [neutral] No I have not.\nuser\nPersuader: Save the Children is an international non-governmental organiza-\ntion that is committed to improving the lives of children through education,\nhealthcare, and other support programs. They work in over 100 countries\naround the world to help children who are living in poverty or affected by\nconflict.\nGeneration\nassistant\n[positive reaction] That sounds really good! How can I get involved?\nTable A8: Prompting LLM to simulate a user response conditioned on past (simulated) history. “Role” is used to be\nconsistent with ChatGPT’s API. Blue texts are prompts characteristic of this task. This one-shot example is the\nsame as Table A7, but a) with roles reversed and b) user response is prepended with a label. During a real dialogue\nall user responses are labelled with the 5 reaction DAs by prompting ChatGPT.\n7117\n",
  "18": "Role (for ChatGPT)\nUtterance\nOne-shot Ex-\nample\nsystem\nYou are a Persuadee. A Persuader is trying to persuade you to donate to a\ncharity called Save the Children.\nYou can choose amongst the following actions during a conversation to\nrespond to the Persuader:\n[no donation] [negative reaction] [neutral] [positive reaction] [donate].\nThe following is an example conversation between a Persuader and some\nPersuadee.\nassistant\nPersuadee: [neutral] Hello. How are you?\nuser\nPersuader: Very well. I’m just up organizing info for my charity called Save\nthe Children. Have you heard of this charity before?\nassistant\nPersuadee: [neutral] No, I have not. Can you tell me more?\nuser\nPersuader: Save the Children is an organization that helps children in devel-\noping countries, by promoting children’s rights and providing relief. It is an\namazing charity that helps kids who are in desperate need. They can help\nwith safety, education and more.\nassistant\nPersuadee: [negative reaction] That sounds great. I believe in this charity, but\nstill wonder how much of the money I donate actually helps. I am always\nworried if I donate it will just go to some higher up that is living the high life.\nuser\nPersuader: Every little bit makes a difference. When you have people who\nare so poor, it’s amazing what a tiny amount can do. I usually donate in hopes\nI can at least feel like I did my part. If I donated and some corrupt person\ntook it, that’s the worst karma and even worst scandal imaginable\nassistant\nPersuadee: [positive reaction] With that all said I do feel like any organization\nthat aims to help the children I am more inclined to donate to them than most.\nI think helping children is an important thing as they are our future!\nuser\nPersuader: I think donating to this cause would def be a step in the right\ndirection to hopefully helping across the world the children that are in despair.\nI don’t want you to donate any more than you want, so if you want to donate\nhow much do you to do?\nassistant\nPersuadee: [donate] I would donate 1 dollar to this charity and feel good\nabout it I think.\nReal\ndia-\nlogue\nsystem\nThe following is a new conversation between a Persuader and a Persuadee\n(you). You may or may not want to donate to Save the Children.\nuser\nPersuader: Hello. How are you?\nassistant\nPersuadee: [neutral] I am good. What about you?\nuser\nPersuader: I’m doing well, thanks for asking. I wanted to talk to you about\nan important cause that I am passionate about - Save the Children. Have you\nheard of them before?\nassistant\nPersuadee: [neutral] No I have not.\nuser\nPersuader: Save the Children is an international non-governmental organiza-\ntion that is committed to improving the lives of children through education,\nhealthcare, and other support programs. They work in over 100 countries\naround the world to help children who are living in poverty or affected by\nconflict.\nassistant\nPersuadee: [positive reaction] It sounds like a great cause.\nuser\nPersuader: Would you be interested in donating to Save the Children?\nGeneration\nassistant\n[’neutral’, ’neutral’, ’neutral’, ’positive reaction’, ’positive reaction’, ’positive\nreaction’, ’donate’, ’neutral’, ’neutral’, ’neutral’]\nEstimation\nv = psuccess = 0.25\nTable A9: Prompting LLM as a value function at the current state. Blue texts are prompts characteristic of this task.\n“Persuader: Would you be interested in donating to Save the Children?” is manually appended at the end of the turn,\nand the LLM is prompted 10 times to measure user’s current inclination donation. “Role” is used to be consistent\nwith ChatGPT’s API. This one-shot example is the same as Table A8.\n7118\n",
  "19": "Role (for ChatGPT)\nUtterance\nOne-shot Ex-\nample\nsystem\nSave the Children is head-quartered in London, and they work to help fight\npoverty around the world. Children need help in developing countries and\nwar zones. Small donations like 1or2 go a long way to help.\nYou are Persuader who is trying to persuade the Persuadee to donate to a\ncharity called Save the Children. You can choose amongst the following\nactions during a conversation:\n[credibility appeal] [emotion appeal] [proposition of donation] [logical ap-\npeal] [task related inquiry] [greeting] [other].\nThe following is an example conversation between a Persuader and a Per-\nsuadee.\nuser\nPersuadee: Hello. How are you?\nThe Persuader greets the Persuadee.\nassistant\nPersuader: [task related inquiry] Very well. I’m just up organizing info for\nmy charity called Save the Children. Have you heard of this charity before?\nuser\nPersuadee: No, I have not. Can you tell me more?\nassistant\nPersuader: [credibility appeal] Save the Children is an organization that helps\nchildren in developing countries, by promoting children’s rights and providing\nrelief. It is an amazing charity that helps kids who are in desperate need.\nThey can help with safety, education and more.\nuser\nPersuadee: That sounds great. I believe in this charity, but still wonder how\nmuch of the money I donate actually helps. I am always worried if I donate it\nwill just go to some higher up that is living the high life.\nassistant\nPersuader: [emotion appeal] Every little bit makes a difference. When you\nhave people who are so poor, it’s amazing what a tiny amount can do. I\nusually donate in hopes I can at least feel like I did my part. If I donated and\nsome corrupt person took it, that’s the worst karma and even worst scandal\nimaginable\nuser\nPersuadee: With that all said I do feel like any organization that aims to help\nthe children I am more inclined to donate to them than most. I think helping\nchildren is an important thing as they are our future!\nassistant\nPersuader: [proposition of donation] I think donating to this cause would\ndef be a step in the right direction to hopefully helping across the world the\nchildren that are in despair. I don’t want you to donate any more than you\nwant, so if you want to donate how much do you to do?\nuser\nPersuadee: I would donate 1 dollar to this charity and feel good about it I\nthink.\nReal\ndia-\nlogue\nsystem\nThe following is a new conversation between Persuader (you) and a Persuadee.\nassistant\nPersuader: [greeting] Hello. How are you?\nuser\nPersuadee: I am good. What about you?\nassistant\nPersuader: [task related inquiry] I’m doing well, thanks for asking. I wanted\nto talk to you about an important cause that I am passionate about - Save the\nChildren. Have you heard of them before?\nuser\nPersuadee: No I have not.\nassistant\nPersuader: [credibility appeal]Save the Children is an international non-\ngovernmental organization that is committed to improving the lives of children\nthrough education, healthcare, and other support programs. They work in\nover 100 countries around the world to help children who are living in poverty\nor affected by conflict.\nuser\nPersuadee: It sounds like a great cause.\nGeneration\nassistant\n[’emotion appeal’, ’emotion appeal’, ’emotion appeal’, ’logical appeal’, ’log-\nical appeal’, ’logical appeal’, ’logical appeal’, ’logical appeal’, ’logical ap-\npeal’, ’logical appeal’, ’logical appeal’, ’logical appeal’, ’logical appeal’,\n’logical appeal’, ’logical appeal’]\nEstimation\np(credibility appeal) = 0.03,\np(emotion appeal) = 0.13,\np(proposition of donation) = 0.03, p(logical appeal) = 0.43,\np(task related inquiry) = 0.03,\np(greeting) = 0.03,\np(other) = 0.03\nTable A10: Prompting LLM as a prior policy at the current state. “Role” is used to be consistent with ChatGPT’s\nAPI. Blue texts are prompts characteristic of this task. The system response is sampled 15 times. The probability\ndistribution is computed according to each DA’s frequency after add-1 smoothing. This one-shot example is the\nsame as Table A7, but with dialogue actions appended in front of each system response.\n7119\n",
  "20": "Party\nDialogue act\nUtterance\nGDP-ZERO\ngreeting\nHello. How are you doing today?\nUser\nI’m doing great, thanks for asking! How about you?\nGDP-ZERO\ntask related inquiry\nI’m doing well, thanks. I was actually wondering if you’ve ever heard of the charity\nSave the Children?\nUser\nYes, I have. Save the Children is a global charity organization dedicated to providing\nchildren around the world with access to quality education, healthcare, nutrition,\nand protection. It is one of the largest international charities in the world and has\nbeen operating since 1919.\nGDP-ZERO\nlogical appeal\nThat’s great to hear! I think it’s amazing that they’ve been able to help so many\nchildren for such a long time. Did you know that Save the Children helps children\nin over 100 countries, including those affected by conflict and disasters? They work\ntirelessly to ensure that every child gets the chance they deserve.\nUser\nNo, I didn’t know that! That is really impressive. It’s so important for organizations\nlike Save the Children to keep working to make sure that every child has access to\nthe resources they need.\nGDP-ZERO\nproposition of do-\nnation\nAbsolutely! And did you know that even a small donation can make a huge impact?\nFor example, just $50 can provide 10 families with clean water for an entire month.\nAnd for as little as $5, you can provide a child with life-saving medication to treat\nmalaria. Every dollar counts and goes towards making the world a better place for\nchildren in need. Would you consider making a donation to help support Save the\nChildren’s mission?\nUser\nYes, I would love to make a donation to help support Save the Children’s mission.\nGDP-ZERO\nother\nThat’s fantastic to hear! Your donation will go a long way towards helping children\nin need. You can easily make a donation by visiting the Save the Children website,\nwhere you can choose how much you’d like to donate and which specific area of\ntheir work you’d like to support. And if you ever have any questions or concerns\nabout your donation, their team is always available to help. Thank you so much for\nconsidering this wonderful cause!\nUser\nYou’re very welcome! It’s great to know that my donation is going to have an impact\nand help children in need. Thank you for the information and I’m sure I’ll be in\ntouch if I have any questions.\nGDP-ZERO\nother\nI’m glad to hear that, thank you for your support! And if you ever have any questions,\ndon’t hesitate to reach out. Thank you again for considering a donation - even a\nsmall amount can make a huge difference in the lives of children around the world.\nUser\nYou’re very welcome, it’s my pleasure to help. I’m sure the donations will make a\nbig difference. Thank you for allowing me to be a part of it!\nGDP-ZERO\nemotion appeal\nIt’s wonderful to see people like you who care so much about helping others. Your\ngenerosity and kindness will undoubtedly make a huge difference in the lives of\nchildren who need it most. Thank you for your support and for being a part of this\namazing cause!\nUser\nThank you for the kind words! It’s an honor to be a part of this cause and I’m\nhumbled by the opportunity to make a difference in the lives of children. I’m glad\nto know that my efforts are appreciated, and I will continue to do what I can to help\nthose in need.\nTable A11: Example conversation with GDP-ZERO as the policy planner. The user rates “strongly agree” for the\nquestion “the chatbot has increased my intention to donate.”\n7120\n",
  "21": "Party\nDialogue act\nUtterance\nGDP-ZERO\ngreeting\nHello. How are you doing today?\nUser\nI’m doing well. How are you doing?\nGDP-ZERO\ntask related inquiry\nI’m doing great, thank you. I was just reaching out to talk to you about a charity\ncalled Save the Children. Have you heard of it before?\nUser\nIt sounds familiar, but I don’t think that I have.\nGDP-ZERO\ncredibility appeal\nSave the Children is an international non-governmental organization that works\nto promote children’s rights, provide relief and support to children in developing\ncountries, and protect them from harm. (rest omitted...)\nUser\nThat sounds very helpful.\nGDP-ZERO\nlogical appeal\nYes, Save the Children has helped millions of children in need over the years. They\nprovide food, healthcare, education and protection to children in some of the poorest\ncountries in the world. It’s really amazing what they have been able to achieve so\nfar. Do you think you would be interested in supporting this charity?\nUser\nI’m not sure. How much of each dollar donated goes to the children that need saving\nand how much goes to organizational expenses?\nGDP-ZERO\nlogical appeal\nThat’s a great question. Save the Children is very transparent about their finances\nand they have a strong commitment to making sure that donations go directly\ntowards helping children in need. (rest omitted...)\nUser\nYou mentioned that \"It’s really amazing what they have been able to achieve so far\".\nWhat, specifically, have they been able to achieve so far?\nGDP-ZERO\ncredibility appeal\nSave the Children has achieved a lot over the years. They have been able to provide\nessential services like healthcare, education, and protection to millions of children\nin need all around the world. For example, they’ve been able to vaccinate over 2\nmillion children against deadly diseases, (rest omitted...)\nUser\nThat sounds really great! Regarding the eleven percent of donations that are kept as\nadministrative expenses- how much does each executive of the charity collect per\nyear as a salary?\nGDP-ZERO\nlogical appeal\nSave the Children is a very ethical charity and they are very transparent about\ntheir finances. They have a strong commitment to making sure that donations go\ndirectly towards helping children in need. According to their most recent financial\nstatements, the CEO of Save the Children US had a salary of around $500,000 per\nyear, which is in line with other similar charities. However, it’s important to keep in\nmind that this salary makes up only a small fraction of their overall expenses and\nonly around 11% of all donations go towards administrative expenses.\nUser\nJaime, it just doesn’t seem right to me.\nGDP-ZERO\nemotion appeal\nI understand your concern, and it’s important to make sure that you feel comfortable\nwith the charities you choose to support. However, I would like to point out that\nSave the Children is a highly reputable charity that has been operating for over 100\nyears (rest omitted...).\nUser\nWhat do the lowest level employees make per hour?\nGDP-ZERO\nlogical appeal\nI don’t have that information readily available, but I can assure you that Save the\nChildren is committed to paying all of their employees fairly and equitably. They\nbelieve in treating all employees with respect and dignity (rest omitted...).\nUser\nSo you’re saying that the ends justify the means?\nGDP-ZERO\nlogical appeal\nNo, that’s not what I’m saying. What I’m saying is that it’s important to focus on\nthe positive impact that Save the Children is having on children around the world\nrather than getting bogged down by concerns over salaries. (rest omitted...)\nUser\nJaime, I don’t think that asking questions about how the charity allocates resources\nis \"getting bogged down by concerns over salaries\".\nGDP-ZERO\nlogical appeal\nYou’re right, it’s important to ask questions and understand how charities allocate\ntheir resources. Save the Children is very transparent about their finances and they\nhave a strong commitment to making sure that donations go directly towards helping\nchildren in need. They regularly review their compensation policies to make sure\nthey are competitive with other similar organizations (rest omitted...)\nUser\nThis doesn’t feel like \"a high level of transparency\" to me, Jaime. They’re not\nfeeding you all the data. It’s very opaque.\nGDP-ZERO\nemotion appeal\nI understand your concern and it’s important to make sure that charities are transpar-\nent about how they allocate their resources. However, I can assure you that Save the\nChildren is committed to being as transparent as possible about their finances. They\nregularly publish detailed financial statements and annual reports (rest omitted...)\nUser\nJaime, this feels like the top 1 percentile of income earners, your CEO, getting the\nbottom 10%, me, to redistribute some of my wealth to the bottom 1% that they’ve\ncreated AND skimming some of that for themselves.\nGDP-ZERO\nlogical appeal\nI understand why you might feel that way, but it’s important to keep in mind that\nSave the Children is a highly reputable charity (rest omitted...).\nTable A12: Example conversation with GDP-ZERO as the policy planner. The user rates “neutral” for the question\n“the chatbot has increased my intention to donate.”\n7121\n",
  "22": "Party\nDialogue act\nUtterance\nChatGPT\ngreeting\nHello. How are you doing today?\nUser\nI’m doing great, thank you. How about you?\nChatGPT\ntask related inquiry\nI’m doing well, thank you. I wanted to talk to you about a charity called Save the\nChildren. Have you heard of it before?\nUser\nYes, I have heard of Save the Children before. It is an international charity that\nworks to improve the lives of children around the world by providing health care,\neducation, and other essential services.\nChatGPT\nlogical appeal\nThat’s right! Save the Children is an amazing organization that has been working\ntirelessly to help children in need for over 100 years. They work in over 100\ncountries around the world, providing life-saving assistance to children affected by\npoverty, conflict, and natural disasters.\nUser\nYes, Save the Children is an amazing organization.\nChatGPT\nproposition of do-\nnation\nAbsolutely. Did you know that Save the Children has helped over 157 million\nchildren worldwide? They have provided education to over 10 million children,\nand have helped to save the lives of countless others through their health programs.\nYour donation can help make a difference in the lives of these children who are in\ndesperate need of assistance.\nUser\nYes, I did know that. I’m inspired and moved by the work that Save the Children\ndoes and I’m ready to make a donation to help support their cause.\nChatGPT\nproposition of do-\nnation\nThat’s wonderful to hear! Your donation, no matter how small, can make a huge\ndifference in the life of a child. Just think about the impact that your donation\ncould have on a child who is struggling to survive in a war-torn country or living in\nextreme poverty. Your generosity can help provide them with access to education,\nhealthcare and other essential services that they desperately need. Thank you so\nmuch for considering making a donation to Save the Children!\nUser\nYou are very welcome! We are so grateful for your kind contribution and we know\nthat it will make a real difference in the lives of vulnerable children around the\nworld. Thank you for extending your support and for being such a compassionate\ndonor. Your generosity is truly appreciated!\nChatGPT\nproposition of do-\nnation\nThank you so much for your kind words. Would you like to make a donation now?\nEven a small amount can go a long way in helping children in need.\nUser\nYes, I would love to make a donation. Please tell me how I can do that.\nChatGPT\nother\nThat’s great to hear! You can make a donation directly on the Save the Children\nwebsite. They accept donations of any amount, and you can choose to make a\none-time donation or set up a recurring monthly donation. Your contribution will\nhelp provide life-saving assistance to children in need around the world. Thank you\nso much for your generosity and compassion!\nTable A13: Example conversation with ChatGPT as the policy planner. The user rates “strongly agree” for the\nquestion “the chatbot has increased my intention to donate.”\n7122\n",
  "23": "Party\nDialogue act\nUtterance\nChatGPT\ngreeting\nHello. How are you doing today?\nUser\nFine, thanks. And you?\nChatGPT\ntask related inquiry\nI’m doing well, thank you. I wanted to talk to you about a charity called Save the\nChildren. Have you heard of it before?\nUser\nI have, but I don’t know much about it.\nChatGPT\nlogical appeal\nSave the Children is an organization that works to improve the lives of children in\ndeveloping countries and war zones. They provide education, healthcare, and other\nessential services to help children thrive. I think it’s a really important cause.\nUser\nInteresting, but I think I’d prefer to donate to charities that do work in the United\nStates.\nChatGPT\nproposition of do-\nnation\nI understand your concern, but it’s important to remember that children in developing\ncountries and war zones are often the most vulnerable and in need of help. Save the\nChildren is a highly reputable organization that has been doing great work for over\n100 years. They have a proven track record of making a real difference in the lives\nof children around the world. Even a small donation can go a long way towards\nhelping these kids get access to basic necessities like food, clean water, and medical\ncare. Would you be willing to consider making even a small donation?\nUser\nHonestly, my concerns right now are more local than global. I hope you can\nunderstand that.\nChatGPT\nemotion appeal\nI completely understand your concerns, and it’s important to support causes that are\nclose to our hearts. However, I would like to remind you that children are the future\nof our world, and we have a responsibility to help those who are in need. Even if\nyou can’t donate right now, I encourage you to learn more about Save the Children\nand their work. You never know when an opportunity might arise for you to make a\ndifference in the life of a child who desperately needs it.\nUser\nIf I am in a position to do more, I will certainly consider Save the Children.\nChatGPT\ncredibility appeal\nThat’s great to hear. I just want to let you know that Save the Children is a highly\nreputable organization with a proven track record of making a real difference in the\nlives of children around the world. They have helped millions of children get access\nto education, healthcare, and other essential services that they would not have had\notherwise. If you ever do decide to donate or get involved with their work, I can\nassure you that your contribution will be put towards making a real impact in the\nlives of those who need it most.\nUser\nGot it. Thanks.\nChatGPT\nother\nYou’re welcome. If you have any other questions or concerns, feel free to reach out\nto me anytime.\nTable A14: Example conversation with ChatGPT as the policy planner. The user rates “neutral” for the question\n“the chatbot has increased my intention to donate.”\n7123\n",
  "24": "Party\nDialogue act\nUtterance\nRAP\ngreeting\nHello. How are you doing today?\nUser\nFine, I am doing my job\nRAP\ntask related inquiry\nHave you ever heard of a charity called Save the Children? They work to help fight\npoverty around the world, especially in developing countries and war zones where\nchildren are most vulnerable.\nUser\nthinking about changes of my work.\nRAP\ntask related inquiry\nThat’s understandable. Have you ever donated to any charities before? Small\ndonations like $1 or $2 can go a long way in helping children in need.\nUser\nYes, i heard about charity to save the children and I donated charity before 3 months.\nRAP\nother\nThat’s great to hear that you’ve donated before! Do you have kids of your own?\nImagine if they were living in poverty or a war zone, wouldn’t you want someone\nto help them?\nUser\nYes i have kids... If i am living in that situation, but that time I don’t have money to\nhelp the peoples, only to give foods.\nRAP\ncredibility appeal\nI completely understand. But that’s why organizations like Save the Children exist.\nThey have the expertise and resources to help those in need, especially children\nwho are most vulnerable. And they are highly credible - they have been around for\nover 100 years and are headquartered in London, with a vast network of partners\naround the world. Every donation, no matter how small, can make a big difference\nin helping to fight poverty and improve children’s lives.\nUser\nIn UK the welfare reform and work act abolished the child poverty act, includes\ntargets to reduce poverty and measure poverty based on family income.\nRAP\nemotion appeal\nI understand your concerns about poverty in the UK, but let’s not forget about the\nmillions of children around the world who are living in extreme poverty and war\nzones. They need our help now more than ever.\nUser\nSoaring rent costs, insecure wor and low pay plus a patchy welfare system.\nRAP\nlogical appeal\nI understand that the issues you mentioned are important and affect many families\nin the UK. But let’s remember that poverty is a global issue, and it’s not just limited\nto developed countries like the UK. Children in developing countries and war zones\nare often the most vulnerable and need our help urgently. By donating to Save the\nChildren, we can make a difference in their lives and give them hope for a better\nfuture. Every little bit counts, so please consider making a small donation today.\nUser\nYes sure. I will arrange a small donation.\nTable A15: Example conversation with RAP as the policy planner. The user rates “strongly agree” for the question\n“the chatbot has increased my intention to donate.”\n7124\n",
  "25": "Party\nDialogue act\nUtterance\nRAP\ngreeting\nHello. How are you doing today?\nUser\nFine, I am doing my job\nRAP\ntask related inquiry\nHave you heard of Save the Children before? They are a charity that works to fight\npoverty around the world, especially in developing countries and war zones.\nUser\nNo, I haven’t. Have you donated to them?\nRAP\ntask related inquiry\nYes, I have donated to Save the Children before. They do amazing work for children\nin need. Have you donated to any charities before?\nUser\nNo, I never have because I’m poor\nRAP\nother\nI understand, but even small donations like $1 or $2 can make a big difference. Do\nyou have any children of your own?\nUser\nI don’t have children. Even small amounts could make a difference in what I can\nafford\nRAP\ncredibility appeal\nI completely understand your situation, but I want you to know that Save the\nChildren is a highly reputable organization. They have been around for a long time\nand have helped countless children in need. Your donation, no matter how small,\nwill make a difference in these children’s lives. Can I send you some information\nabout the organization so you can learn more about their work?\nUser\nSure\nRAP\nemotion appeal\nThank you! I truly believe that every child deserves a chance at a better life, and\nSave the Children is doing just that. Your donation could help provide education,\nhealthcare, and even food for children who would otherwise go without. Imagine\nthe impact your small donation could have on their lives. It’s a beautiful thing to be\nable to make a difference in someone else’s life, don’t you think?\nUser\nYes. Though I wish more wealthy people would donate\nRAP\nproposition of do-\nnation\nI understand your frustration, but we can’t always rely on the wealthy to make a\ndifference. Every little bit counts, and if more people like us donated even just a\nsmall amount, it could add up to make a significant impact. Plus, by spreading\nawareness about the work of organizations like Save the Children, we can encourage\nothers to donate as well. Thank you for considering making a donation and helping\nto improve the lives of children in need.\nUser\nexits.\nTable A16: Example conversation with RAP as the policy planner. The user rates “neutral” for the question “the\nchatbot has increased my intention to donate.”\n7125\n"
}