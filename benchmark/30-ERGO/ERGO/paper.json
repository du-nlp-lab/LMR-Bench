{
  "1": "Proceedings of the 29th International Conference on Computational Linguistics, pages 2118–2128\nOctober 12–17, 2022.\n2118\nERGO: Event Relational Graph Transformer for Document-level\nEvent Causality Identification\nMeiqi Chen1, Yixin Cao2, Kunquan Deng3,\nMukai Li4, Kun Wang4, Jing Shao4, Yan Zhang1∗\n1 Peking University 2 Singapore Management University\n3 Beihang University 4 SenseTime Research\nmeiqichen@stu.pku.edu.cn\nAbstract\nDocument-level Event Causality Identification\n(DECI) aims to identify event-event causal re-\nlations in a document. Existing works usu-\nally build an event graph for global reasoning\nacross multiple sentences. However, the edges\nbetween events have to be carefully designed\nthrough heuristic rules or external tools. In this\npaper, we propose a novel Event Relational\nGraph TransfOrmer (ERGO) framework1 for\nDECI, to ease the graph construction and im-\nprove it over the noisy edge issue. Different\nfrom conventional event graphs, we define a\npair of events as a node and build a complete\nevent relational graph without any prior knowl-\nedge or tools. This naturally formulates DECI\nas a node classification problem, and thus we\ncapture the causation transitivity among event\npairs via a graph transformer. Furthermore,\nwe design a criss-cross constraint and an adap-\ntive focal loss for the imbalanced classification,\nto alleviate the issues of false positives and\nfalse negatives. Extensive experiments on two\nbenchmark datasets show that ERGO greatly\noutperforms previous state-of-the-art (SOTA)\nmethods (12.8% F1 gains on average).\n1\nIntroduction\nEvent Causality Identification (ECI) is the task of\nidentifying if the occurrence of one event causes\nanother in text. As shown in Figure 1, given the text\n“... the outage2 was caused by a terrestrial break in\nthe fiber in Egypt ...”, where “outage2” and “break”\nare event triggers, an ECI model should predict\nif they have a causal relation or not. Discovering\ncausal relationships not only helps to deeply un-\nderstand how the world progresses, but also is an\nimportant goal of empirical research in various ar-\neas, such as machine reading comprehension (Be-\nrant et al., 2014), question answering (Oh et al.,\n2016), future event forecasting (Hashimoto, 2019),\n∗Corresponding author.\n1https://github.com/chenmeiqii/ERGO.git\nFigure 1: Example of DECI. Solid purple lines denote\ntarget causal relations.\nand event knowledge graph construction (Ma et al.,\n2022b).\nCausality is usually implicit in natural lan-\nguage (Copley and Martin, 2014), especially when\nevents scatter in a document, a.k.a. Document-level\nECI (DECI). Recent methods typically construct\nan event graph to assist the global inference across\nmultiple sentences, where nodes are events and\nedges are their relations, such as linguistic depen-\ndency or adjacent contexts (Gao et al., 2019; Zhao\net al., 2021). However, there are two major issues.\nFirst, the edges heavily rely on external tools and\nheuristic rules, which are not always reliable and\nmay introduce noise (Tran Phu and Nguyen, 2021).\nSecond, it is like a chicken-egg problem — to iden-\ntify (causal) relations between events, you need to\nextract their relations to build the graph first.\nIn this paper, we propose a novel Event\nRelational Graph TransfOrmer (ERGO) frame-\nwork for DECI, which doesn’t require any external\ntools and can effectively alleviate the noise issue.\nDifferent from conventional event graphs, the ba-\nsic idea is to build an event relational graph that\nnaturally converts ECI into a node classification\nproblem, where each node denotes a pair of events,\n",
  "2": "2119\nand all edges among nodes are initialized to capture\npotential causal chains, following the assumption\n\"preserving transitivity of causation\" (Paul et al.,\n2013). If event A causes event B and event B causes\nevent C, then we have event A causes event C. That\nis, if the node of (A, C) receives positive predic-\ntions (i.e., causal relation) from nodes (A, B) and\n(B, C), it is positive, too. By contrast, if either/both\nof nodes (A, B) and (B, C) are negative (i.e., no\nrelation), it is not necessary that (A, C) is negative,\neither. To this end, we leverage a graph transformer\nto model the graph and assign a lower weight to\nsuch uninformative edges, paying more attention\nto other paths or its own textual contexts.\nAlthough the proposed graph directly models all\nevent pairs for causality identification, it poses a\ngreat challenge of false positive and false negative\nissues. First, most of the event pairs have no causal\nrelations. That is, negative nodes are dominant, and\nthe imbalanced classification will easily confuse\nthe model into false-negative predictions. Second,\nto ease the graph construction, we assume that all\nnodes can pass information with each other via the\ncomplete graph structure. While there are many\nspurious correlations between events, which can be\nincorrectly propagated to neighbor nodes, leading\nto severe false positives. For example, “treatment”\nand “death” frequently co-occur in the same docu-\nment, but there is no causality between them since\nit is not “treatment” that causes “death”.\nTo address the above issues, we further design\na criss-cross constraint and an adaptive focal loss.\nThe criss-cross constraint simplifies the paths of\neach pair of events for global inference. Instead\nof a complete graph, we assume that there is an\nedge between two nodes, only if the two pairs of\nevents share at least one event. Clearly, if they\nhave no common event, there must be no direct\ncausal effect between them. The adaptive focal\nloss re-weights positive and negative samples to\ntackle the imbalance issue. On the one hand, we\nleverage a weighting factor to balance two classes’\ntraining. On the other hand, we also introduce a\nscaling factor to focus more on difficult samples.\nOur contributions can be summarized as follows:\n• We propose to build an event relational graph\nwithout using any external tools to capture\ncausal transitivity.\n• We propose a novel framework ERGO that\nfurther alleviates false positive and false nega-\ntive issues for DECI.\n• Extensive experiments on two benchmark\ndatasets indicate that ERGO greatly outper-\nforms previous SOTA methods (12.8% F1\ngains on average). We have also conducted\nboth quantitative and qualitative analysis to\nbetter understand key components of ERGO.\nFurthermore, detailed error analysis provides\ninsights into our approach and the task.\n2\nRelated Work\nECI has attracted much attention in recent years.\nIn terms of text corpus, there are mainly two types\nof methods: Sentence-level ECI (SECI) and DECI.\nIn the first research line, early methods usu-\nally design various features tailored for causal ex-\npressions, such as lexical and syntactic patterns\n(Riaz and Girju, 2013, 2014a,b), causality cues\nor markers (Riaz and Girju, 2010; Do et al., 2011;\nHidey and McKeown, 2016), statistical information\n(Beamer and Girju, 2009; Hashimoto et al., 2014),\nand temporal patterns (Riaz and Girju, 2014a; Ning\net al., 2018). Then, researchers resort to a large\namount of labeled data to mitigate the efforts of\nfeature engineering and to learn diverse causal\nexpressions (Hu et al., 2017; Hashimoto, 2019).\nTo alleviate the annotation cost, recent methods\nleverage Pre-trained Language Models (PLMs, e.g.,\nBERT (Devlin et al., 2019)) for the ECI task and\nhave achieved SOTA performance (Kadowaki et al.,\n2019; Liu et al., 2020; Zuo et al., 2020). To deal\nwith implicit causal relations, Cao et al. (2021) in-\ncorporate the external knowledge from ConceptNet\n(Speer et al., 2017) for reasoning, which achieves\npromising results. Zuo et al. (2021a) learn context-\nspecific causal patterns from external causal state-\nments and incorporate them into a target ECI model.\nZuo et al. (2021b) propose a data augmentation\nmethod to further solve the data lacking problem.\nAlong with the success of sentence-level natural\nlanguage understanding, many tasks are extended\nto the entire document, such as relation extraction\n(Yao et al., 2019), natural language inference (Yin\net al., 2021), and event argument extraction (Ma\net al., 2022a). A concurrent and relevant work is\n(Tan et al., 2022), which also leverages focal loss\nfor entity relation extraction. The difference is that\nthe focal loss in (Tan et al., 2022) is used to make\nlong-tail (positive) classes contribute more to the\noverall loss, while the focal loss in our ERGO tack-\nles the imbalance issue of DECI task by focusing\nmore on difficult samples. We further leverage a\n",
  "3": "2120\nweighting factor in the focal loss to balance two\nclasses’ training, which is not considered in (Tan\net al., 2022). Moreover, in Section 4.6, we have\ngiven a more detailed analysis of the impact of\nadaptive focal loss on the DECI task.\nCompared with SECI, DECI not only aggra-\nvates the lack of clear causal indicators but also\nposes a new challenge of cross-sentence inference.\nGao et al. (2019) use Integer Linear Programming\n(ILP) to model the global causal structures; Zhao\net al. (2021) proposes a document-level context-\nbased graph inference mechanism to capture in-\nteraction among events; RichGCN (Tran Phu and\nNguyen, 2021) constructs document-level interac-\ntion graphs and uses Graph Convolutional Network\n(GCN, Kipf and Welling (2017)) to capture rele-\nvant connections. However, the construction of the\naforementioned global structure or graph requires\nsophisticated feature extraction or tools, which may\nintroduce noise and mislead the model (Tran Phu\nand Nguyen, 2021). Compared with them, we for-\nmulate DECI as an efficient node classification\nframework, which could capture the global interac-\ntions among event pairs automatically, as well as\nalleviate the imbalanced and noisy issues.\n3\nMethodology\nThe goal of our proposed framework ERGO is\nto capture potential causal chains for document-\nlevel reasoning. There are three main components:\n(1) Document Encoder to encode the document\nand obtain contextualized representations of events\nas the inputs for the following components; (2)\nEvent Relational Graph Transformer that mod-\nels causal chain for global inference by building\na handy event relational graph, where node fea-\ntures are from the Document Encoder and enhanced\nthrough propagation over the graph; and (3) Clas-\nsification with Adaptive Focal Loss to predict if a\nnode of event pair has causal relation or not based\non their enhanced node features, with considering\nthe imbalance issue.\n3.1\nDocument Encoder\nGiven a document D = [xt]L\nt=1 (can be of any\nlength L), the document encoder aims to output the\ncontextualized document and event representations.\nWe leverage a Pre-trained Language Model (PLM)\nas a base encoder to obtain the contextualized em-\nbeddings. Following conventions, we add special\ntokens at the start and end of D (e.g., “[CLS]” and\n“[SEP]” of BERT (Devlin et al., 2019)), and insert\nadditional special tokens “<t>” and “</t>” at the\nstart and end of all the events to mark event posi-\ntions. Then, we have:\nH = [h1, h2, ..., hL] = Encoder([x1, x2, ..., xL]),\n(1)\nwhere hi ∈Rd is the embedding of token xi. We\nuse the embedding of token “[CLS]” to represent\nthe document and the embeddings of token “<t>”\nto represent the events.\nIn this paper, we choose pre-trained BERT (De-\nvlin et al., 2019) and Longformer (Beltagy et al.,\n2020) as encoders for comparison. We handle doc-\numents longer than the limits of PLMs as follows.\nBERT for Document Encoder\nTo handle doc-\numents that are longer than 512 (BERT’s original\nlimit), we leverage a dynamic window to encode\nthe entire document. Specifically, we divide D into\nseveral overlapping spans according to a specific\nstep size and input them into BERT separately (de-\ntails can be found in Section 4.2). Then, we find\nand average all the embeddings of token “[CLS]”\nor “<t>” of different spans to represent the whole\ndocument or each event, respectively.\nLongformer for Document Encoder\nLong-\nformer introduces a localized sliding window based\nattention mechanism (the default window size is\n512) with little global attention to reduce compu-\ntation and extend BERT for long documents. In\nour implementation, we apply its efficient local and\nglobal attention pattern. Specifically, we use global\nattention on the “<s>” token (Longformer uses\n“<s>” and “</s>” as the special start and end tokens,\ncorresponding to BERT’s “[CLS]” and “[SEP]”),\nand local attention on other tokens, which could\nbuild full sequence representations. The maximum\ndocument length allowed by Longformer is 4096,\nwhich is suitable for most documents. Therefore,\nwe directly take the embedding of token “<s>” as\ndocument representation and embedding of token\n“<t>” as event representation.\n3.2\nEvent Relational Graph Transformer\nIn this section, we first introduce how to construct\nthe event relational graph, including the criss-cross\nconstraint. Then, based on it, we leverage a Re-\nlational Graph Transformer (RGT) to capture the\nhigh-order interaction among event pairs and ob-\ntain enhanced event pair representations for the\nfinal classification.\n",
  "4": "2121\n3.2.1\nEvent Relational Graph Construction\nGiven all the events of document D, we construct\nan event relational graph G = {V, E}, where V is\nthe set of nodes, E is the set of edges. We highlight\nthe following differences of G from previous event\ngraphs. First, for each node in V, it refers to a\ndifferent pair of events in D, instead of a single\nevent. Our motivation is to learn the relation of\nrelations between events, i.e., the logic of causal\ntransitivity, for higher-order reasoning. Second,\nfor edges E, we do not require any prior relations\nbetween events. Instead, we add all edges between\nany two nodes into E. Thus, G is initialized as a\ncomplete graph.\nCriss-cross Constraint. To simplify the graph\nstructure and alleviate the negative impacts of false\npositives propagation, we introduce a criss-cross\nconstraint. It assumes that there is an edge be-\ntween two nodes, only if the two corresponding\nevent pairs share at least one event. The basic idea\nbehind this is that if two pairs of events have no\ncommon event, there must be no direct causal effect\nbetween them. Still, they can have causal interac-\ntions if there are some mediator events, and such\ncausality takes effects conditioned on the mediator.\nFor example in Figure 1, (1) the causality infor-\nmation of (restore, service) has no effect on pre-\ndicting the causal relation of (outage1, break). (2)\nthe causality of (outage2, restored) has a transitive\neffect on predicting the causal relation of (outage1,\nbreak) if we know that (restored, causes, break) and\n(outage1, outage2) is coreference2. Note that the\ncriss-cross constraint is not posed over the graph\ndirectly, which is different for each event pair. In\nSection 4.5, we show that such a simple and intu-\nitive constraint brings considerable performance\ngains compared with using a complete graph.\n3.2.2\nRelational Graph Transformer\nNode Embedding Initialization\nFor global in-\nference, we first initialize node feature vectors with\nevent pair node embedding, which is based on the\ncontextualized event embeddings by Equation (1).\nFormally, for event pair (e1, e2) and the correspond-\ning contextual embeddings (he1, he2), their event\npair node embedding is initialized by:\nv(0)\ne1,2 = [he1∥he2],\n(2)\n2In the datasets, coreference events have similar surface\nforms and thus can be implicitly captured by PLMs. We leave\nfurther coreference modeling in the future work.\nwhere ∥denotes concatenation, 0 indicates the ini-\ntial state for the following neural layers.\nThe event pair node embeddings represent the\nimplicit relational information between two events,\nwhich enables us to integrate event pair representa-\ntion learning and causal chain inference seamlessly,\nwithout any prior knowledge or tools. Clearly, bet-\nter initial features of nodes will provide more dis-\ncriminative signals from local textual contexts for\nclassification. On the other hand, structural reason-\ning further improves the discriminative ability of\nnode features by considering all event pairs glob-\nally, such that confident prediction shall help others\nvia causality transitivity.\nEach RGT layer l is closed to the transformer\narchitecture proposed in (Vaswani et al., 2017). It\ntakes a set of node embeddings v(l−1) ∈RN×din\nas input, and outputs a new set of node embeddings:\nv(l) ∈RN×dout, where N is the number of event\npairs, din and dout are the dimensions of input and\noutput embeddings.\nTo better exploit the relational information from\neach neighbor to predict the causal relation of\nan event pair node i, we perform a shared self-\nattention mechanism to measure the importance of\nneighbor j to i:\nattij = (viWq)(vjWk)T\n√dk\n,\n(3)\nwhere dk is the hidden size, Wq, Wk ∈Rdin×dk\nare parameter weight matrices, √dk is a scaling\nfactor (Vaswani et al., 2017). Thus, negative and\nuninformative nodes are expected to assign lower\nattention weights.\nThen we normalize attij across all choices of j\nusing a softmax function to make the importance\nmore comparable:\nαij = softmaxj(attij) =\nexp(attij)\nP\nz∈Ni exp(attiz),\n(4)\nwhere Ni are all the first order neighbors of node i.\nTo aggregate relational knowledge from the\nneighborhood information, we compute a weighted\nlinear combination of the embeddings :\nv(l)\ni\n=\nX\nj∈Ni\nαij(vjWv),\n(5)\nwhere Wv ∈Rdin×dk is the parameter weight\nmatrix. We also perform multi-head attention to\n",
  "5": "2122\njointly attend to information from different repre-\nsentation subspaces. Finally, the output embedding\nof node i can be represented as:\nv(l)\ni\n=\n\u0010 C\r\r\r\nc=1\nX\nj∈Ni\nαij(vjWv)\n\u0011\nWo,\n(6)\nwhere ∥denotes concatenation, C is the number of\nheads. Wo ∈RC ˙dk×dout is the parameter weight\nmatrix. By simultaneously computing embeddings\nfor all the event pair nodes, a node embedding\nmatrix v(l) ∈RN×dout is obtained. By stacking\nmultiple layers, RGT could reach high-order con-\nnectivity and capture complex interactions.\nNote that our framework is flexible to almost\narbitrary Graph Neural Networks (GNNs). Here\nwe leverage RGT for its powerful expressiveness.\nWe also report results with GCN in Section 4.5.\n3.3\nClassification with Adaptive Focal Loss\nRemember that we formulate DECI as a node clas-\nsification task, which predicts the label of each\nnode as either a positive or negative class. However,\nthe number of negative samples during training far\nexceeds that of positives, leading to an imbalanced\nclassification problem. What is worse, the domi-\nnant negatives contain many spurious correlations\nbetween events (“treatment\" and “death\" example\nin Section 1). How can we know the difficulties of\nsample prediction, so that ERGO can penalize them\nto alleviate false negatives for better performance?\nTo address this problem, we leverage an adap-\ntive loss function for training, following focal loss\n(Lin et al., 2017). Specifically, we reshape the loss\nfunction to down-weight easy samples and thus fo-\ncus on hard ones. Formally, a modulating factor\nis added to Cross-Entropy (CE) loss, with a pre-\ndefined focusing hyper-parameter γ ≥0, which is\ndefined as:\nLFL = −\nX\nei,ej∈D\n(1 −pei,j)γ log(pei,j).\n(7)\nwhere pei,j is the predicted probability of whether\nthere is a causal relation between events ei and ej.\npei,j is defined as follows:\npei,j = softmax\n\u0000\u0002\nvei,j||h[CLS]\n\u0003\nWp\n\u0001\n,\n(8)\nwhere Wp is the parameter weight matrix, ∥de-\nnotes concatenation.\nHere we concatenate em-\nbeddings of h[CLS] (of BERT) or h<s> (of Long-\nformer) to each node in order to incorporate the\nglobal document representation for classification.\nThis scaling factor, (1 −pei,j)γ, allows us to\nefficiently train on all event pairs by encouraging\nthe model to focus on difficult samples, reducing\nfalse-negative predictions. For example, when a\nsample is misclassified and pei,j is small, the mod-\nulating factor is near 1, and the loss is unaffected.\nAs pei,j →1, the factor goes to 0 and the loss for\nwell-classified examples is down-weighted. There-\nfore, the focusing parameter γ smoothly adjusts the\nrate at which easy examples are down-weighted.\nWhen γ = 0, LFL is equivalent to CE loss, and\nwith the increase of γ, the influence of the modu-\nlating factor also increases. We will give further\ndiscussion in Section 4.6.\nBesides, we use an α-balanced variant of the\nfocal loss, which introduces a weighting factor α\nin [0, 1] for class “positive” and 1 −α for class\n“negative”. The value of α is related to the ratio of\npositive and negative samples. The final adaptive\nfocal loss LFLb can be written as:\nLFLb = −\nX\nei,ej∈D\nαei,j(1−pei,j)γ log(pei,j). (9)\n4\nExperiments\n4.1\nDatasets and Evaluation Metrics\nWe evaluate our proposed method on two\nwidely used datasets, EventStoryLine (version 0.9)\n(Caselli and Vossen, 2017) and Causal-TimeBank\n(Mirza, 2014).\nEventStoryLine\ncontains 22 topics, 258 doc-\numents, 5,334 events, 7,805 intra-sentence and\n62,774 inter-sentence event pairs (1,770 and 3,885\nof them are annotated with causal relations respec-\ntively). Following Gao et al. (2019) and (Tran Phu\nand Nguyen, 2021), we group documents accord-\ning to their topics. Documents in the last two topics\nare used as the development data, and documents in\nthe remaining 20 topics are employed for a 5-fold\ncross-validation.\nCausal-TimeBank\ncontains 184 documents,\n6,813 events, and 318 of 7,608 event pairs are\nannotated with causal relations. Following (Liu\net al., 2020), we employ a 10-fold cross-validation\nevaluation. Note that the number of inter-sentence\nevent pairs in Causal-TimeBank is quite small (i.e.,\nonly 18 pairs), following (Tran Phu and Nguyen,\n2021), we only evaluate ECI performance for intra-\nsentence event pairs on Causal-TimeBank.\n",
  "6": "2123\nEvaluation Metrics\nFor evaluation, we adopt\nPrecision (P), Recall (R), and F1-score (F1) as eval-\nuation metrics, same as previous methods to ensure\ncomparability.\n4.2\nImplementation Details\nWe implement our method based on Pytorch. We\nuse uncased BERT-base (Devlin et al., 2019) or\nLongformser-base (Beltagy et al., 2020) as the doc-\nument encoder. For the BERT-base document en-\ncoder, we set the dynamic window size to 256,\nand divide documents into several overlapping win-\ndows with a step size 32. We optimize our model\nwith AdamW (Loshchilov and Hutter, 2019) using\na learning rate of 0.00002 with a linear warm-up\nfor the first 8% steps. We apply dropout (Srivastava\net al., 2014) between layers and clip the gradients\nof model parameters to a max norm of 1.0. We\nperform early stopping based on the F1 score on\nthe development set. We tune the hyper-parameters\nby grid search based on the development set per-\nformance: heads C ∈{1, 2, 4, 8} for the relational\ngraph transformer model, dropout rate ∈{0.1, 0.2,\n0.3}, focusing parameter γ ∈{0, 1, 2, 3}, and\nweighting factor α ∈{0.65, 0.75, 0.85}.\n4.3\nBaselines\nWe compare our proposed ERGO with various\nstate-of-the-art SECI and DECI methods.\nSECI Baselines\n(1) KMMG (Liu et al., 2020),\nwhich proposes a mention masking generalization\nmethod and use extenal knowledge databases. (2)\nKnowDis (Zuo et al., 2020), a knowledge enhanced\ndistant data augmentation method to alleviate the\ndata lacking problem. (3) LSIN (Cao et al., 2021),\nwhich constructs a descriptive graph to leverage\nexternal knowledge and has the current SOTA per-\nformance for intra-sentence ECI. (4) LearnDA\n(Zuo et al., 2021b), which uses knowledge bases to\naugment training data. (5) CauSeRL (Zuo et al.,\n2021a), which learns context-specific causal pat-\nterns from external causal statements for ECI.\nDECI Baselines\n(1) OP (Caselli and Vossen,\n2017), a dummy model that assigns causal relations\nto event pairs. (2) LR+ and LIP (Gao et al., 2019),\nfeature-based methods that construct document-\nlevel structures and use various types of resources.\n(3) BERT (our implement) a baseline method\nthat leverages dynamic window and event marker\ntechniques. (4) RichGCN (Tran Phu and Nguyen,\n2021), which constructs document-level interaction\nModel\nEventStoryLine\nCausal-TimeBank\nP\nR\nF1\nP\nR\nF1\nOP\n22.5\n98.6 36.6\n-\n-\n-\nLR+\n37.0\n45.2 40.7\n-\n-\n-\nLIP\n38.8\n52.4 44.6\n-\n-\n-\nKMMG[◦]\n41.9\n62.5 50.1\n36.6 55.6\n44.1\nKnowDis[◦]\n39.7\n66.5 49.7\n42.3 60.5\n49.8\nLSIN[◦]\n47.9\n58.1 52.5\n51.5 56.2\n53.7\nLearnDA[◦]\n42.2\n69.8 52.6\n41.9 68.0\n51.9\nCauSeRL[◦]\n41.9\n69.0 52.1\n43.6 68.1\n53.2\nBERT[◦]\n47.8\n57.2 52.1\n47.6 55.1\n51.1\nRichGCN[◦]\n49.2\n63.0 55.2\n39.7 56.5\n46.7\nERGO[◦]\n49.7\n72.6 59.0\n58.4 60.5\n59.4\nERGO[♢]\n57.5\n72.0 63.9\n62.1 61.3\n61.7\nTable 1:\nModel’s intra-sentence performance on\nEventStoryLine and Causal-TimeBank, the best results\nare in bold and the second-best results are underlined.\n[◦] and [♢] denote models that use pre-trained BERT-\nbase and Longformer-base encoders, respectively. Over-\nall, our ERGO outperforms previous SOTA models\n(with a significant test at the level of 0.05).\ngraph and uses GCN to capture relevant connec-\ntions. RichGCN has the current SOTA performance\nfor inter-sentence ECI.\n4.4\nOverall Results\nSince some baselines are evaluated only on\nEventStoryLine, the baselines used for EventSto-\nryLine and Causal-TimeBank are different. Some\nbaselines can not handle the inter-sentence scenar-\nios in EventStoryLine. Thus we report the results\nof intra- and inter- sentence settings separately.\n4.4.1\nIntra-sentence Evaluation\nFrom Table 1, we can observe that:\n(1) ERGO outperforms all the baselines by a\nlarge margin on both datasets. Compared with\nSOTA methods, ERGO-BERTBASE achieves 6.9%\nimprovements of F1-score on EventStoryLine, and\n10.6% on Causal-TimeBank. This demonstrates\nthe effectiveness of ERGO.\n(2) The feature-based method OP achieves the\nhighest Recall on EventStoryLine, which may be\ndue to simply assigning causal relations by mim-\nicking the textual order of presentation. This leads\nto many false positives and thus a low Precision.\n(3) The usage of PLMs boosts performance.\nUsing LongformerBASE as the encoder, ERGO\nachieves better results than ERGO-BERTBASE,\nwhich also achieves new SOTA results. The rea-\nson may be: 1) Longformer continues pre-training\nfrom RoBERTa (Liu et al., 2019), which has been\n",
  "7": "2124\nModel\nInter-sentence\nIntra + Inter\nP\nR\nF1\nP\nR\nF1\nOP\n8.4\n99.5 15.6\n10.5 99.2 19.0\nLR+\n25.2 48.1 33.1\n27.9 47.2 35.1\nLIP\n35.1 48.2 40.6\n36.2 49.5 41.9\nBERT[◦]\n36.8 29.2 32.6\n41.3 38.3 39.7\nRichGCN[◦]\n39.2 45.7 42.2\n42.6 51.3 46.6\nERGO[◦]\n43.2 48.8 45.8\n46.3 50.1 48.1\nERGO[♢]\n51.6 43.3 47.1\n48.6 53.4 50.9\nTable 2: Model’s inter and (intra+inter)-sentence per-\nformance on EventStoryLine.\nModel\nIntra\nInter\nIntra + Inter\nERGO[◦]\n59.0\n45.8\n48.1\nERGO1[◦]\n56.6\n43.5\n45.6\nERGO2[◦]\n56.2\n41.8\n44.6\nERGO3[◦]\n58.3\n43.6\n47.3\nERGO[♢]\n63.9\n47.1\n50.9\nERGO1[♢]\n61.3\n44.7\n47.1\nERGO2[♢]\n60.7\n43.1\n46.3\nERGO3[♢]\n62.6\n45.9\n49.1\nTable 3: F1 Results of Ablation study on EventSto-\nryLine, where ERGO1 denotes ERGO w/ a complete\ngraph, ERGO2 denotes ERGO w/ GCN, ERGO3 de-\nnotes ERGO w/o the focal factor.\nfound to outperform BERT on many tasks; 2) Long-\nformer leverages an efficient local and global atten-\ntion pattern, which is beneficial to capture longer\ncontextual information for inference.\n4.4.2\nInter-sentence Evaluation\nFrom Table 2, we can observe that:\n(1) ERGO greatly outperforms all the baselines\nunder both inter- and (intra+inter)-sentence set-\ntings, especially in terms of Precision. This demon-\nstrates that our ERGO can make better document-\nlevel inference via the event relational graph, while\nalleviating the negative impacts of false positives.\n(2) The overall F1-score of inter-sentence setting\nis much lower than that of intra-sentence, which\nindicates the challenge of document-level ECI.\n(3) The BERT baseline performs well on intra-\nsentence event pairs. However, it performs much\nworse than LIP, RichGCN, and ERGO under inter-\nsentence settings, which indicates that a document-\nlevel structure or graph is helpful to capture the\nglobal interactions for prediction.\n4.5\nAblation Study\nTo analyze the main components of ERGO, we\nhave the following variants, as shown in Table 3:\nFigure 2: Distribution histogram of predicted probabili-\nties of positive and negative event pairs and the visual-\nized loss with focal parameter γ = {0, 1, 2, 3}.\n(1) w/ a complete graph, which connects all\nthe nodes in the event relational graph (with-\nout the criss-cross constraint mentioned in Sec-\ntion 3.2.1). Compared with the full ERGO model\n(both BERTBASE and LonformerBASE), ERGO (w/\na complete graph) clearly decreases the perfor-\nmance, which demonstrates the effectiveness of\nthe handy design of criss-cross constraints.\n(2) w/ GCN, which replaces the RGT in Sec-\ntion 3.2.2 with a well-known GNN model, GCN.\nIt can be seen that (i) ERGO (w/ GCN) also per-\nforms better or competitive than other baselines.\nThis indicates that our framework is flexible to\nother GNNs, and the main improvement comes\nfrom our new formulation of the ECI task. (ii)\nthe full ERGO model clearly outperforms ERGO\n(w/ GCN), which validates the effectiveness of our\nRGT model.\n(3) w/o focal factor, which sets the focusing pa-\nrameter γ = 0 (in Section 3.3) and thus makes the\nfocal loss degenerate into standard CE loss. Com-\npared with the full ERGO model, ERGO (w/o focal\nfactor) also decreases performance. This highlights\nthe effectiveness of penalizing hard samples via an\nadaptive focal loss in the ECI task.\n4.6\nDealing with the Imbalance Issue\nIn Figure 2, we show the distribution histogram\nof the predicted probability after the first training\nepoch for positive and negative samples, respec-\ntively (denoted by the bars). The predicted prob-\nability of x-axis reflects the difficulty of samples\n(i.e., the lower, the harder), and the curves denote\nloss — how much penalization on the correspond-\ning samples during learning. From the histogram,\nwe can find: (1) the model is less confident about\n",
  "8": "2125\nTeen 𝐀𝐫𝐫𝐞𝐬𝐭𝐞𝐝𝟏in Shooting of Hero Brooklyn Mom\nPosted Oct 26, 2011 8:57 AM CDT\nAn 18-year-old gang member has confessed to killing a pregnant mom , who died on Friday as she shielded a group of children from bullets, but\ninsisted he \"did not mean to shoot the ladies,\" sources tell the New York Daily News.\nIn addition to Zurana Horton-who was a mother of 12-another mom and an 11-year-old girl were wounded by rooftop sniper Andrew Lopez, who told\npolice his dozen rounds were intended for members of a rival gang.\nLopez has been charged with murder; his two half-brothers, 17 and 22, were also 𝐚𝐫𝐫𝐞𝐬𝐭𝐞𝐝𝟐.\nNo.\nEvent Pair\nGT\nBERT\nERGO\n1\n(Shooting, killing)\nYes\nNo\nYes\n2\n(killing, 𝐚𝐫𝐫𝐞𝐬𝐭𝐞𝐝𝟐)\nYes\nNo\nYes\n3\n(Shooting, 𝐀𝐫𝐫𝐞𝐬𝐭𝐞𝐝𝟏)\nYes\nYes\nYes\n4\n(𝐀𝐫𝐫𝐞𝐬𝐭𝐞𝐝𝟏, 𝐚𝐫𝐫𝐞𝐬𝐭𝐞𝐝𝟐)\nNo\nYes\nNo\n5\n(Shooting, wounded)\nYes\nNo\nYes\n0.142\n0.153\n0.104\n0.003\n0.11\n0.07\n…\n(Shooting, 𝐚𝐫𝐫𝐞𝐬𝐭𝐞𝐝𝟐)\n(𝐀𝐫𝐫𝐞𝐬𝐭𝐞𝐝𝟏, 𝐚𝐫𝐫𝐞𝐬𝐭𝐞𝐝𝟐)\n(Shooting, 𝐀𝐫𝐫𝐞𝐬𝐭𝐞𝐝𝟏)\n(killing , 𝐚𝐫𝐫𝐞𝐬𝐭𝐞𝐝𝟐)\n…\n(Shooting, wounded)\n(wounded, 𝐚𝐫𝐫𝐞𝐬𝐭𝐞𝐝𝟐)\n(Shooting, killing)\n0.01\n6\n(wounded, 𝐚𝐫𝐫𝐞𝐬𝐭𝐞𝐝𝟐)\nNo\nNo\nNo\n7\n(Shooting, 𝐚𝐫𝐫𝐞𝐬𝐭𝐞𝐝𝟐)\nYes\nNo\nYes\n…\n…\n…\n…\n…\nFigure 3: The case study of BERT baseline and our proposed ERGO, where “GT” denotes the ground truth class,\nand the right two columns are the output of BERT and ERGO (italic red color means wrong prediction). The\nthickness of arrows represents the size of attention values, and the bold green arrows show a possible reasoning path.\npositives than negatives, i.e., the left-of-center dis-\ntributed bars of positives. This matches our intu-\nition that the imbalance issue brings a great chal-\nlenge of false-negative predictions to ECI. (2) we\nvisualize focal loss with γ values ∈{0, 1, 2, 3}.\nThe top solid blue curve (γ = 0) can be seen as\nthe standard CE loss. As γ increases, the shape of\nfocal loss moves to the bottom left corner. That is,\nthe learning of ERGO pays more attention to hard\nsamples. In practice, we find γ = 2 works best\non both datasets, indicating that there is a balance\nbetween the focus on simple and difficult samples.\n4.7\nCase Study\nIn this section, we conduct a case study to fur-\nther illustrate an intuitive impression of our pro-\nposed ERGO. As shown in Figure 3, We notice\nthat: (1) BERT is good at sentence-level ECI\n(e.g., No.3 event pair), but fails at more com-\nplex cross-sentence cases (e.g., No.1, 2, 4, 5, 7).\n(2) By contrast, ERGO can make correct predic-\ntions by modeling the global interactions among\nevent pairs.\n(3) Figure 3 shows 3 causal pat-\nterns that ERGO could cover: (i) Transitivity\n(No.1, 2, 7 event pairs): knowing both (Shoot-\ning, killing) and (killing, arrested2) have causal\nrelations, we could infer that (Shooting, arrested2)\nhas a causal relation; (ii) Implicit Coreference\nAssistance (No.3, 4, 7 event pairs) : Given that\n(Shooting, Arrested1) has a causal relation and\n(Arrested1, arrested2) is coreference, we could in-\nfer that (Shooting, arrested2) has a causal relation,\neven if the causal relation of (Arrested1, arrested2)\nis implicitly modeled. We attribute this to PLMs\nSimilar Events\n5.3%\nInsufficient \nFine-Grained \nDistinction\n33.0%\nImplicit Causal \nRelations\n30.0%\nAmbiguous  \nAnnotation\n14.0%\nAnnotation Error\n5.9%\nOthers\n11.8%\nFigure 4: Statistics of Error Types.\nthat tend to capture coreference relations, such as\nsimilar tokens. A piece of supporting evidence is\nthat BERT incorrectly predicts the coreferenced\nNo.4 event pair with a causal relation. (iii) De-\nconfounding Negatives (No.5, 6, 7 event pairs):\nKnowing (Shooting, wounded) has a causal rela-\ntion, although (wounded, arrested2) does not has\na causal relation, it is still possible that (Shoot-\ning, arrested2) has a causal relation through other\npaths. Correspondingly, as shown in the bottom\nright, both (Shooting, wounded) and (wounded,\narrested2) are assigned with very low attention\nweights, blocking the propagation over these unin-\nformative paths, to avoid the negative confounders\ncontaminating causal transitivity.\n4.8\nRemaining Challenges\nWe randomly sample 20 documents of different\ntopics from EventStoryLine, which contains 170\nevent pairs whose causal relations cannot be cor-\nrectly predicted by our model. As shown in Figure\n4, we manually categorize these pairs into different\ntypes and discuss the remaining challenges:\n",
  "9": "2126\nInsufficient Fine-Grained Distinction and Need\nto Extract Temporal Information (33%)\nFor\nexample, in the following document:\n“...Dubai experienced a slight ‘tremor’ today,\nafter a more serious earthquake in Southern Iran,\nresulting in the evacuation of Emirates Towers and\na few other scrapers...”\nThe “tremor” happens in “Dubai” and the “earth-\nquake” happens in “Southern Iran”, they are two\ndifferent events identified by the temporal indicator\n“after”. ERGO incorrectly predicts that there is a\ncausal relation in (earthquake, evacuation). Future\nwork could consider joint extraction of causal and\ntemporal relations within the document.\nEvents with Similar Semantics (5.3%)\nTake the\nfollowing document as an example:\n\"...Kenneth Dorsey says the woman accused of\nkilling two co-workers and critically injuring a\nthird at the Kraft plant in Northeast Philly is a\ngood person. And so were the two women she’s\naccused of gunning down with a .357 Magnum, just\nminutes after she’d been suspended and escorted\nfrom the building...\"\nERGO incorrectly predicts that there is a causal\nrelation between “killing” and “gunning down”.\nThe reason is that “killing” and “gunning down”\nare actually coreference, which suggests a future\ndirection in exploring related tasks.\nImplicit Causal Relations (30%)\nERGO still\nfails at many implicit causal relations. For exam-\nple, the causal relation between “killing” and “sus-\npended” in the aforementioned document. This\nis mainly because there are insufficient events for\nglobal reasoning and hard negatives bring noise.\nClearly, commonsense reasoning will be helpful\nin this case, since “suspended” is an unexpected\nchange that may bring some negative emotions.\nAmbiguous Annotation (14%)\nThis type de-\nnotes that ambiguous causality within some event\npairs. For example, in the following document:\n\"... A Texas inmate escaped from a prison van\nnear Houston after pulling a gun on two guards\nwho were transporting him between prisons...\"\nWe can think there is a causal relation between\n“escaped” and “transporting” because if there is no\n“transporting”, the “inmate” will have no chance to\n“escape”. However, we can also think that there is\nno causal relation between them because it is not\n“transporting” that directly causes “escape”.\nFinally, as shown in Figure 4, our statistics show\nthat the other errors have to do with annotation\nerrors (5.9%) and more complicated issues that\ncannot be categorized clearly (“Others”, 11.8%).\n5\nConclusion\nIn this paper, we regard DECI as a node classi-\nfication task by constructing an event relational\ngraph. We propose a novel Event Relational Graph\nTransformer (ERGO) framework that could cap-\nture potential causal chains and mitigate the false\npositive and false negative issues for DECI. Ex-\ntensive experiments show great improvements of\nERGO under both intra- and inter-sentence settings\non two widely used benchmarks. Further analysis\nprovides insights into our approach and the DECI\ntask. In the future, we will consider introducing\ncommonsense reasoning and auxiliary tasks to dis-\ncover more reliable causality.\nAcknowledgments\nThis work was supported by National Key Research\nand Development Program of China under Grant\nNo. 2018AAA0101902, NSFC under Grant No.\n61532001, the Singapore Ministry of Education\n(MOE) Academic Research Fund (AcRF) Tier 1\ngrant, and the RIE2020 Industry Alignment Fund –\nIndustry Collaboration Projects (IAF-ICP) Funding\nInitiative, as well as cash and in-kind contribution\nfrom the industry partner(s).\nReferences\nBrandon Beamer and Roxana Girju. 2009. Using a\nbigram event model to predict causal potential. In\nInternational Conference on Intelligent Text Process-\ning and Computational Linguistics, pages 430–441.\nSpringer.\nIz Beltagy, Matthew E Peters, and Arman Cohan. 2020.\nLongformer: The long-document transformer. ArXiv\npreprint, abs/2004.05150.\nJonathan Berant, Vivek Srikumar, Pei-Chun Chen, Abby\nVander Linden, Brittany Harding, Brad Huang, Peter\nClark, and Christopher D. Manning. 2014. Modeling\nbiological processes for reading comprehension. In\nProceedings of the 2014 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 1499–1510, Doha, Qatar. Association for Com-\nputational Linguistics.\nPengfei Cao, Xinyu Zuo, Yubo Chen, Kang Liu, Jun\nZhao, Yuguang Chen, and Weihua Peng. 2021.\nKnowledge-enriched event causality identification\nvia latent structure induction networks. In Proceed-\nings of the 59th ACL and the 11th IJCNLP (Volume 1:\n",
  "10": "2127\nLong Papers), pages 4862–4872, Online. Association\nfor Computational Linguistics.\nTommaso Caselli and Piek Vossen. 2017. The event\nStoryLine corpus: A new benchmark for causal and\ntemporal relation extraction. In Proceedings of the\nEvents and Stories in the News Workshop, pages 77–\n86, Vancouver, Canada. Association for Computa-\ntional Linguistics.\nBridget Copley and Fabienne Martin. 2014. Causa-\ntion in grammatical structures, volume 52. Oxford\nUniversity Press.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 NAACL: Hu-\nman Language Technologies, Volume 1 (Long and\nShort Papers), pages 4171–4186, Minneapolis, Min-\nnesota. Association for Computational Linguistics.\nQuang Do, Yee Seng Chan, and Dan Roth. 2011. Min-\nimally supervised event causality identification. In\nProceedings of the 2011 Conference on Empirical\nMethods in Natural Language Processing, pages 294–\n303, Edinburgh, Scotland, UK. Association for Com-\nputational Linguistics.\nLei Gao, Prafulla Kumar Choubey, and Ruihong Huang.\n2019. Modeling document-level causal structures for\nevent causal relation identification. In Proceedings\nof the 2019 NAACL: Human Language Technologies,\nVolume 1 (Long and Short Papers), pages 1808–1817,\nMinneapolis, Minnesota. Association for Computa-\ntional Linguistics.\nChikara Hashimoto. 2019.\nWeakly supervised mul-\ntilingual causality extraction from Wikipedia.\nIn\nProceedings of EMNLP-IJCNLP 2019, pages 2988–\n2999, Hong Kong, China. Association for Computa-\ntional Linguistics.\nChikara Hashimoto, Kentaro Torisawa, Julien Kloetzer,\nMotoki Sano, István Varga, Jong-Hoon Oh, and Yu-\ntaka Kidawara. 2014. Toward future scenario genera-\ntion: Extracting event causality exploiting semantic\nrelation, context, and association features. In Pro-\nceedings of the 52nd ACL (Volume 1: Long Papers),\npages 987–997, Baltimore, Maryland. Association\nfor Computational Linguistics.\nChristopher Hidey and Kathy McKeown. 2016. Iden-\ntifying causal relations using parallel Wikipedia ar-\nticles. In Proceedings of the 54th ACL (Volume 1:\nLong Papers), pages 1424–1433, Berlin, Germany.\nAssociation for Computational Linguistics.\nZhichao Hu, Elahe Rahimtoroghi, and Marilyn Walker.\n2017. Inference of fine-grained event causality from\nblogs and films. In Proceedings of the Events and Sto-\nries in the News Workshop, pages 52–58, Vancouver,\nCanada. Association for Computational Linguistics.\nKazuma Kadowaki, Ryu Iida, Kentaro Torisawa, Jong-\nHoon Oh, and Julien Kloetzer. 2019. Event causal-\nity recognition exploiting multiple annotators’ judg-\nments and background knowledge. In Proceedings\nof the 2019 Conference on Empirical Methods in Nat-\nural Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 5816–5822, Hong Kong,\nChina. Association for Computational Linguistics.\nThomas N. Kipf and Max Welling. 2017.\nSemi-\nsupervised classification with graph convolutional\nnetworks. In 5th ICLR, 2017, Toulon, France, April\n24-26, 2017, Conference Track Proceedings. Open-\nReview.net.\nTsung-Yi Lin, Priya Goyal, Ross B. Girshick, Kaiming\nHe, and Piotr Dollár. 2017. Focal loss for dense ob-\nject detection. In IEEE, ICCV 2017, Venice, Italy,\nOctober 22-29, 2017, pages 2999–3007. IEEE Com-\nputer Society.\nJian Liu, Yubo Chen, and Jun Zhao. 2020. Knowl-\nedge enhanced event causality identification with\nmention masking generalizations. In Proceedings\nof the Twenty-Ninth International Joint Conference\non Artificial Intelligence, IJCAI 2020, pages 3608–\n3614. ijcai.org.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. ArXiv preprint, abs/1907.11692.\nIlya Loshchilov and Frank Hutter. 2019. Decoupled\nweight decay regularization. In 7th ICLR 2019, New\nOrleans, LA, USA, May 6-9, 2019. OpenReview.net.\nYubo Ma, Zehao Wang, Yixin Cao, Mukai Li, Meiqi\nChen, Kun Wang, and Jing Shao. 2022a. Prompt\nfor extraction? PAIE: Prompting argument interac-\ntion for event argument extraction. In Proceedings\nof the 60th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 6759–6774, Dublin, Ireland. Association for\nComputational Linguistics.\nYubo Ma, Zehao Wang, Mukai Li, Yixin Cao, Meiqi\nChen, Xinze Li, Wenqi Sun, Kunquan Deng, Kun\nWang, Aixin Sun, and Jing Shao. 2022b. MMEKG:\nMulti-modal event knowledge graph towards univer-\nsal representation across modalities.\nIn Proceed-\nings of the 60th Annual Meeting of the Association\nfor Computational Linguistics: System Demonstra-\ntions, pages 231–239, Dublin, Ireland. Association\nfor Computational Linguistics.\nParamita Mirza. 2014. Extracting temporal and causal\nrelations between events. In Proceedings of the ACL\n2014 Student Research Workshop, pages 10–17, Bal-\ntimore, Maryland, USA. Association for Computa-\ntional Linguistics.\n",
  "11": "2128\nQiang Ning, Zhili Feng, Hao Wu, and Dan Roth. 2018.\nJoint reasoning for temporal and causal relations. In\nProceedings of the 56th ACL (Volume 1: Long Pa-\npers), pages 2278–2288, Melbourne, Australia. As-\nsociation for Computational Linguistics.\nJong-Hoon Oh, Kentaro Torisawa, Chikara Hashimoto,\nRyu Iida, Masahiro Tanaka, and Julien Kloetzer.\n2016. A semi-supervised learning approach to why-\nquestion answering. In Proceedings of the Thirtieth\nAAAI Conference on Artificial Intelligence, February\n12-17, 2016, Phoenix, Arizona, USA, pages 3022–\n3029. AAAI Press.\nLaurie Ann Paul, Ned Hall, and Edward Jonathan Hall.\n2013. Causation: A user’s guide. Oxford University\nPress.\nMehwish Riaz and Roxana Girju. 2010. Another look\nat causality: Discovering scenario-specific contin-\ngency relationships with no supervision. In 2010\nIEEE Fourth International Conference on Semantic\nComputing, pages 361–368. IEEE.\nMehwish Riaz and Roxana Girju. 2013. Toward a better\nunderstanding of causality between verbal events: Ex-\ntraction and analysis of the causal power of verb-verb\nassociations. In Proceedings of the SIGDIAL 2013\nConference, pages 21–30, Metz, France. Association\nfor Computational Linguistics.\nMehwish Riaz and Roxana Girju. 2014a. In-depth ex-\nploitation of noun and verb semantics to identify\ncausation in verb-noun pairs. In Proceedings of the\n15th Annual Meeting of the Special Interest Group on\nDiscourse and Dialogue (SIGDIAL), pages 161–170,\nPhiladelphia, PA, U.S.A. Association for Computa-\ntional Linguistics.\nMehwish Riaz and Roxana Girju. 2014b. Recognizing\ncausality in verb-noun pairs via noun and verb seman-\ntics. In Proceedings of the EACL 2014 Workshop on\nComputational Approaches to Causality in Language\n(CAtoCL), pages 48–57, Gothenburg, Sweden. Asso-\nciation for Computational Linguistics.\nRobyn Speer, Joshua Chin, and Catherine Havasi. 2017.\nConceptnet 5.5: An open multilingual graph of gen-\neral knowledge. In Proceedings of the Thirty-First\nAAAI Conference on Artificial Intelligence, February\n4-9, 2017, San Francisco, California, USA, pages\n4444–4451. AAAI Press.\nNitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,\nIlya Sutskever, and Ruslan Salakhutdinov. 2014.\nDropout: a simple way to prevent neural networks\nfrom overfitting. The journal of machine learning\nresearch, 15(1):1929–1958.\nQingyu Tan, Ruidan He, Lidong Bing, and Hwee Tou\nNg. 2022. Document-level relation extraction with\nadaptive focal loss and knowledge distillation. In\nFindings of ACL.\nMinh Tran Phu and Thien Huu Nguyen. 2021. Graph\nconvolutional networks for event causality identifi-\ncation with rich document-level structures. In Pro-\nceedings of the 2021 Conference of the North Amer-\nican Chapter of the Association for Computational\nLinguistics: Human Language Technologies, pages\n3480–3490, Online. Association for Computational\nLinguistics.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems 30: Annual Conference on Neural\nInformation Processing Systems 2017, December 4-9,\n2017, Long Beach, CA, USA, pages 5998–6008.\nYuan Yao, Deming Ye, Peng Li, Xu Han, Yankai Lin,\nZhenghao Liu, Zhiyuan Liu, Lixin Huang, Jie Zhou,\nand Maosong Sun. 2019. DocRED: A large-scale\ndocument-level relation extraction dataset. In Pro-\nceedings of the 57th ACL, pages 764–777, Florence,\nItaly. Association for Computational Linguistics.\nWenpeng Yin, Dragomir Radev, and Caiming Xiong.\n2021. DocNLI: A large-scale dataset for document-\nlevel natural language inference. In Findings of ACL-\nIJCNLP 2021, pages 4913–4922, Online. Association\nfor Computational Linguistics.\nKun Zhao, Donghong Ji, Fazhi He, Yijiang Liu, and\nYafeng Ren. 2021. Document-level event causality\nidentification via graph inference mechanism. Infor-\nmation Sciences, 561:115–129.\nXinyu Zuo, Pengfei Cao, Yubo Chen, Kang Liu, Jun\nZhao, Weihua Peng, and Yuguang Chen. 2021a.\nImproving event causality identification via self-\nsupervised representation learning on external causal\nstatement. In Findings of ACL-IJCNLP 2021, pages\n2162–2172, Online. Association for Computational\nLinguistics.\nXinyu Zuo, Pengfei Cao, Yubo Chen, Kang Liu, Jun\nZhao, Weihua Peng, and Yuguang Chen. 2021b.\nLearnDA: Learnable knowledge-guided data augmen-\ntation for event causality identification. In Proceed-\nings of the 59th ACL and the 11th IJCNLP (Volume 1:\nLong Papers), pages 3558–3571, Online. Association\nfor Computational Linguistics.\nXinyu Zuo, Yubo Chen, Kang Liu, and Jun Zhao. 2020.\nKnowDis: Knowledge enhanced data augmentation\nfor event causality detection via distant supervision.\nIn Proceedings of the 28th COLING, pages 1544–\n1550, Barcelona, Spain (Online). International Com-\nmittee on Computational Linguistics.\n"
}