{"id": 73, "timestamp": "2025-05-16T21:48:47.830375", "source": "agent", "message": "I read the file /workspace/benchmark/datasets/19-Native-Sparse-Attention/NSA/native_sparse_attention/ops/parallel.py.", "cause": 72, "observation": "read", "tool_call_metadata": {"function_name": "str_replace_editor", "tool_call_id": "toolu_08", "model_response": {"id": "chatcmpl-BY1tMJsiJjfTrMi4dw34GTf1psc6h", "created": 1747450124, "model": "o4-mini-2025-04-16", "object": "chat.completion", "system_fingerprint": null, "choices": [{"finish_reason": "stop", "index": 0, "message": {"content": "", "role": "assistant", "tool_calls": [{"index": 1, "function": {"arguments": "{\"command\": \"view\", \"path\": \"/workspace/benchmark/datasets/19-Native-Sparse-Attention/NSA/native_sparse_attention/ops/parallel.py\"}", "name": "str_replace_editor"}, "id": "toolu_08", "type": "function"}], "function_call": null}}], "usage": {"completion_tokens": 157, "prompt_tokens": 21435, "total_tokens": 21592, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 64, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "service_tier": "default"}, "total_calls_in_response": 1}, "content": "Here's the result of running `cat -n` on /workspace/benchmark/datasets/19-Native-Sparse-Attention/NSA/native_sparse_attention/ops/parallel.py:\n     1\t# -*- coding: utf-8 -*-\n     2\t# Copyright (c) 2023-2025, Songlin Yang, Yu Zhang\n     3\t\n     4\timport warnings\n     5\tfrom typing import Optional, Union\n     6\t\n     7\timport torch\n     8\timport triton\n     9\timport triton.language as tl\n    10\tfrom einops import rearrange\n    11\t\n    12\tfrom fla.ops.common.utils import (prepare_chunk_indices, prepare_chunk_offsets,\n    13\t                                  prepare_lens, prepare_token_indices)\n    14\tfrom fla.ops.utils import mean_pooling\n    15\tfrom fla.utils import autocast_custom_bwd, autocast_custom_fwd, contiguous\n    16\tfrom native_sparse_attention.ops.utils import _bitonic_merge\n    17\t\n    18\ttry:\n    19\t    from flash_attn import flash_attn_func, flash_attn_varlen_func\n    20\texcept ImportError:\n    21\t    warnings.warn(\n    22\t        \"Flash Attention is not installed. Please install it via `pip install flash-attn --no-build-isolation`\",\n    23\t        category=ImportWarning\n    24\t    )\n    25\t    flash_attn_func = None\n    26\t\n    27\t\n    28\t@triton.heuristics({\n    29\t    'USE_OFFSETS': lambda args: args['offsets'] is not None\n    30\t})\n    31\t@triton.autotune(\n    32\t    configs=[\n    33\t        triton.Config({}, num_warps=num_warps)\n    34\t        for num_warps in [1, 2, 4]\n    35\t    ],\n    36\t    key=['BS', 'BK', 'BV'],\n    37\t)\n    38\t@triton.jit\n    39\tdef parallel_nsa_compression_fwd_kernel(\n    40\t    q,\n    41\t    k,\n    42\t    v,\n    43\t    o,\n    44\t    lse,\n    45\t    scale,\n    46\t    offsets,\n    47\t    token_indices,\n    48\t    chunk_offsets,\n    49\t    T,\n    50\t    H: tl.constexpr,\n    51\t    HQ: tl.constexpr,\n    52\t    G: tl.constexpr,\n    53\t    K: tl.constexpr,\n    54\t    V: tl.constexpr,\n    55\t    BC: tl.constexpr,\n    56\t    BS: tl.constexpr,\n    57\t    BK: tl.constexpr,\n    58\t    BV: tl.constexpr,\n    59\t    USE_OFFSETS: tl.constexpr,\n    60\t):\n    61\t    i_t, i_v, i_bh = tl.program_id(0), tl.program_id(1), tl.program_id(2)\n    62\t    i_b, i_h = i_bh // H, i_bh % H\n    63\t\n    64\t    if USE_OFFSETS:\n    65\t        i_n, i_t = tl.load(token_indices + i_t * 2).to(tl.int32), tl.load(token_indices + i_t * 2 + 1).to(tl.int32)\n    66\t        bos, eos = tl.load(offsets + i_n).to(tl.int32), tl.load(offsets + i_n + 1).to(tl.int32)\n    67\t        T = eos - bos\n    68\t        boc = tl.load(chunk_offsets + i_n).to(tl.int32)\n    69\t    else:\n    70\t        bos, eos = i_b * T, i_b * T + T\n    71\t        boc = i_b * tl.cdiv(T, BS)\n    72\t\n    73\t    p_q = tl.make_block_ptr(q + (bos + i_t) * HQ*K, (HQ, K), (K, 1), (i_h * G, 0), (G, BK), (1, 0))\n    74\t\n    75\t    # the Q block is kept in the shared memory throughout the whole kernel\n    76\t    # [G, BK]\n    77\t    b_q = tl.load(p_q, boundary_check=(0, 1))\n    78\t    b_q = (b_q * scale).to(b_q.dtype)\n    79\t\n    80\t    # the number of compression representations in total\n    81\t    TC = tl.cdiv(T, BS)\n    82\t    # the number of compression representations required to iterate over\n    83\t    # incomplete compression blocks are not included\n    84\t    NC = (i_t + 1) // BS\n    85\t\n    86\t    p_o = tl.make_block_ptr(o + (bos + i_t) * HQ*V, (HQ, V), (V, 1), (i_h * G, i_v * BV), (G, BV), (1, 0))\n    87\t    # [G, BV]\n    88\t    b_o = tl.zeros([G, BV], dtype=tl.float32)\n    89\t    # max scores for the current block\n    90\t    b_m = tl.full([G], float('-inf'), dtype=tl.float32)\n    91\t    # lse = log(acc) + m\n    92\t    b_acc = tl.zeros([G], dtype=tl.float32)\n    93\t\n    94\t    for i_c in range(0, NC, BC):\n    95\t        o_c = i_c + tl.arange(0, BC)\n    96\t\n    97\t        p_k = tl.make_block_ptr(k + (boc * H + i_h) * K, (K, TC), (1, H*K), (0, i_c), (BK, BC), (0, 1))\n    98\t        p_v = tl.make_block_ptr(v + (boc * H + i_h) * V, (TC, V), (H*V, 1), (i_c, i_v * BV), (BC, BV), (1, 0))\n    99\t        # [BK, BC]\n   100\t        b_k = tl.load(p_k, boundary_check=(0, 1))\n   101\t        # [BC, BV]\n   102\t        b_v = tl.load(p_v, boundary_check=(0, 1))\n   103\t        # [G, BC]\n   104\t        b_s = tl.dot(b_q, b_k)\n   105\t        b_s = tl.where((o_c < NC)[None, :], b_s, float('-inf'))\n   106\t\n   107\t        # [G]\n   108\t        b_m, b_mp = tl.maximum(b_m, tl.max(b_s, 1)), b_m\n   109\t        b_r = tl.exp(b_mp - b_m)\n   110\t        # [G, BC]\n   111\t        b_p = tl.exp(b_s - b_m[:, None])\n   112\t        # [G]\n   113\t        b_acc = b_acc * b_r + tl.sum(b_p, 1)\n   114\t\n   115\t        # [G, BV]\n   116\t        b_o = b_o * b_r[:, None] + tl.dot(b_p.to(b_q.dtype), b_v)\n   117\t\n   118\t        b_mp = b_m\n   119\t    if NC == 0:\n   120\t        b_lse = tl.zeros([G], dtype=tl.float32)\n   121\t    else:\n   122\t        b_o = b_o / b_acc[:, None]\n   123\t        b_lse = b_m + tl.log(b_acc)\n   124\t\n   125\t    tl.store(p_o, b_o.to(p_o.dtype.element_ty), boundary_check=(0, 1))\n   126\t    if i_v == 0:\n   127\t        tl.store(lse + (bos + i_t) * HQ + i_h * G + tl.arange(0, G), b_lse.to(lse.dtype.element_ty))\n   128\t\n   129\t\n   130\t@triton.heuristics({\n   131\t    'USE_OFFSETS': lambda args: args['offsets'] is not None,\n   132\t})\n   133\t@triton.autotune(\n   134\t    configs=[\n   135\t        triton.Config({}, num_warps=num_warps)\n   136\t        for num_warps in [1, 2, 4]\n   137\t    ],\n   138\t    key=['BS', 'BK', 'BV'],\n   139\t)\n   140\t@triton.jit(do_not_specialize=['T'])\n   141\tdef parallel_nsa_compression_bwd_kernel_dq(\n   142\t    q,\n   143\t    k,\n   144\t    v,\n   145\t    lse,\n   146\t    delta,\n   147\t    do,\n   148\t    dq,\n   149\t    scale,\n   150\t    offsets,\n   151\t    token_indices,\n   152\t    chunk_offsets,\n   153\t    T,\n   154\t    B: tl.constexpr,\n   155\t    H: tl.constexpr,\n   156\t    HQ: tl.constexpr,\n   157\t    G: tl.constexpr,\n   158\t    K: tl.constexpr,\n   159\t    V: tl.constexpr,\n   160\t    BC: tl.constexpr,\n   161\t    BS: tl.constexpr,\n   162\t    BK: tl.constexpr,\n   163\t    BV: tl.constexpr,\n   164\t    USE_OFFSETS: tl.constexpr\n   165\t):\n   166\t    i_t, i_v, i_bh = tl.program_id(0), tl.program_id(1), tl.program_id(2)\n   167\t    i_b, i_h = i_bh // H, i_bh % H\n   168\t\n   169\t    if USE_OFFSETS:\n   170\t        i_n, i_t = tl.load(token_indices + i_t * 2).to(tl.int32), tl.load(token_indices + i_t * 2 + 1).to(tl.int32)\n   171\t        bos, eos = tl.load(offsets + i_n).to(tl.int32), tl.load(offsets + i_n + 1).to(tl.int32)\n   172\t        T = eos - bos\n   173\t        boc = tl.load(chunk_offsets + i_n).to(tl.int32)\n   174\t    else:\n   175\t        bos, eos = i_b * T, i_b * T + T\n   176\t        boc = i_b * tl.cdiv(T, BS)\n   177\t\n   178\t    q += (bos + i_t) * HQ*K\n   179\t    do += (bos + i_t) * HQ*V\n   180\t    lse += (bos + i_t) * HQ\n   181\t    delta += (bos + i_t) * HQ\n   182\t    dq += (i_v * B * T + bos + i_t) * HQ*K\n   183\t\n   184\t    p_q = tl.make_block_ptr(q, (HQ, K), (K, 1), (i_h * G, 0), (G, BK), (1, 0))\n   185\t    p_dq = tl.make_block_ptr(dq, (HQ, K), (K, 1), (i_h * G, 0), (G, BK), (1, 0))\n   186\t\n   187\t    # [G, BK]\n   188\t    b_q = tl.load(p_q, boundary_check=(0, 1))\n   189\t    b_q = (b_q * scale).to(b_q.dtype)\n   190\t\n   191\t    p_do = tl.make_block_ptr(do, (HQ, V), (V, 1), (i_h * G, i_v * BV), (G, BV), (1, 0))\n   192\t    p_lse = lse + i_h * G + tl.arange(0, G)\n   193\t    p_delta = delta + i_h * G + tl.arange(0, G)\n   194\t\n   195\t    # the number of compression representations in total\n   196\t    TC = tl.cdiv(T, BS)\n   197\t    # the number of compression representations required to iterate over\n   198\t    # incomplete compression blocks are not included\n   199\t    NC = (i_t + 1) // BS\n   200\t\n   201\t    # [G, BV]\n   202\t    b_do = tl.load(p_do, boundary_check=(0, 1))\n   203\t    # [G]\n   204\t    b_lse = tl.load(p_lse)\n   205\t    b_delta = tl.load(p_delta)\n   206\t\n   207\t    # [G, BK]\n   208\t    b_dq = tl.zeros([G, BK], dtype=tl.float32)\n   209\t    for i_c in range(0, NC, BC):\n   210\t        o_c = i_c + tl.arange(0, BC)\n   211\t        p_k = tl.make_block_ptr(k + (boc * H + i_h) * K, (K, TC), (1, H*K), (0, i_c), (BK, BC), (0, 1))\n   212\t        p_v = tl.make_block_ptr(v + (boc * H + i_h) * V, (V, TC), (1, H*V), (i_v * BV, i_c), (BV, BC), (0, 1))\n   213\t        # [BK, BC]\n   214\t        b_k = tl.load(p_k, boundary_check=(0, 1))\n   215\t        # [BV, BC]\n   216\t        b_v = tl.load(p_v, boundary_check=(0, 1))\n   217\t\n   218\t        # [G, BC]\n   219\t        b_s = tl.dot(b_q, b_k)\n   220\t        b_p = tl.exp(b_s - b_lse[:, None])\n   221\t        b_p = tl.where((o_c < NC)[None, :], b_p, 0)\n   222\t\n   223\t        # [G, BV] @ [BV, BC] -> [G, BC]\n   224\t        b_dp = tl.dot(b_do, b_v)\n   225\t        b_ds = b_p * (b_dp.to(tl.float32) - b_delta[:, None])\n   226\t        # [G, BC] @ [BC, BK] -> [G, BK]\n   227\t        b_dq += tl.dot(b_ds.to(b_k.dtype), tl.trans(b_k))\n   228\t    b_dq *= scale\n   229\t    tl.store(p_dq, b_dq.to(p_dq.dtype.element_ty), boundary_check=(0, 1))\n   230\t\n   231\t\n   232\t@triton.heuristics({\n   233\t    'USE_OFFSETS': lambda args: args['offsets'] is not None\n   234\t})\n   235\t@triton.autotune(\n   236\t    configs=[\n   237\t        triton.Config({}, num_warps=num_warps)\n   238\t        for num_warps in [1, 2, 4]\n   239\t    ],\n   240\t    key=['BS', 'BK', 'BV'],\n   241\t)\n   242\t@triton.jit(do_not_specialize=['T'])\n   243\tdef parallel_nsa_compression_bwd_kernel_dkv(\n   244\t    q,\n   245\t    k,\n   246\t    v,\n   247\t    lse,\n   248\t    delta,\n   249\t    do,\n   250\t    dk,\n   251\t    dv,\n   252\t    offsets,\n   253\t    chunk_indices,\n   254\t    chunk_offsets,\n   255\t    scale,\n   256\t    T,\n   257\t    B: tl.constexpr,\n   258\t    H: tl.constexpr,\n   259\t    HQ: tl.constexpr,\n   260\t    G: tl.constexpr,\n   261\t    K: tl.constexpr,\n   262\t    V: tl.constexpr,\n   263\t    BC: tl.constexpr,\n   264\t    BS: tl.constexpr,\n   265\t    BK: tl.constexpr,\n   266\t    BV: tl.constexpr,\n   267\t    USE_OFFSETS: tl.constexpr\n   268\t):\n   269\t    i_v, i_c, i_bh = tl.program_id(0), tl.program_id(1), tl.program_id(2)\n   270\t    i_b, i_h = i_bh // H, i_bh % H\n   271\t\n   272\t    if USE_OFFSETS:\n   273\t        i_n, i_c = tl.load(chunk_indices + i_c * 2).to(tl.int32), tl.load(chunk_indices + i_c * 2 + 1).to(tl.int32)\n   274\t        bos, eos = tl.load(offsets + i_n).to(tl.int32), tl.load(offsets + i_n + 1).to(tl.int32)\n   275\t        T = eos - bos\n   276\t        boc = tl.load(chunk_offsets + i_n).to(tl.int32)\n   277\t    else:\n   278\t        bos, eos = i_b * T, i_b * T + T\n   279\t        boc = i_b * tl.cdiv(T, BS)\n   280\t\n   281\t    # the number of compression representations in total\n   282\t    TC = tl.cdiv(T, BS)\n   283\t\n   284\t    p_k = tl.make_block_ptr(k + (boc * H + i_h) * K, (TC, K), (H*K, 1), (i_c * BC, 0), (BC, BK), (1, 0))\n   285\t    p_v = tl.make_block_ptr(v + (boc * H + i_h) * V, (TC, V), (H*V, 1), (i_c * BC, i_v * BV), (BC, BV), (1, 0))\n   286\t    p_dk = tl.make_block_ptr(dk + (i_v * B*T*H + boc * H + i_h) * K, (TC, K), (H*K, 1), (i_c * BC, 0), (BC, BK), (1, 0))\n   287\t    p_dv = tl.make_block_ptr(dv + (i_v * B*T*H + boc * H + i_h) * V, (TC, V), (H*V, 1), (i_c * BC, i_v * BV), (BC, BV), (1, 0))\n   288\t\n   289\t    # [BC, BK]\n   290\t    b_k = tl.load(p_k, boundary_check=(0, 1))\n   291\t    b_dk = tl.zeros([BC, BK], dtype=tl.float32)\n   292\t    # [BC, BV]\n   293\t    b_v = tl.load(p_v, boundary_check=(0, 1))\n   294\t    b_dv = tl.zeros([BC, BV], dtype=tl.float32)\n   295\t\n   296\t    for i in range(i_c * BC * BS, T):\n   297\t        o_c = i_c * BC + tl.arange(0, BC)\n   298\t\n   299\t        p_q = tl.make_block_ptr(q + (bos + i) * HQ*K, (HQ, K), (K, 1), (i_h * G, 0), (G, BK), (1, 0))\n   300\t        # [G, BK]\n   301\t        b_q = tl.load(p_q, boundary_check=(0, 1))\n   302\t        b_q = (b_q * scale).to(b_q.dtype)\n   303\t\n   304\t        p_do = tl.make_block_ptr(do + (bos + i) * HQ*V, (HQ, V), (V, 1), (i_h * G, i_v * BV), (G, BV), (1, 0))\n   305\t        p_lse = lse + (bos + i) * HQ + i_h * G + tl.arange(0, G)\n   306\t        p_delta = delta + (bos + i) * HQ + i_h * G + tl.arange(0, G)\n   307\t        # [G, BV]\n   308\t        b_do = tl.load(p_do, boundary_check=(0, 1))\n   309\t        # [G]\n   310\t        b_lse = tl.load(p_lse)\n   311\t        b_delta = tl.load(p_delta)\n   312\t        # [BC, G]\n   313\t        b_s = tl.dot(b_k, tl.trans(b_q))\n   314\t        b_p = tl.exp(b_s - b_lse[None, :])\n   315\t        b_p = tl.where((i >= max(0, (o_c + 1) * BS - 1))[:, None], b_p, 0)\n   316\t        # [BC, G] @ [G, BV] -> [BC, BV]\n   317\t        b_dv += tl.dot(b_p.to(b_do.dtype), b_do)\n   318\t        # [BC, BV] @ [BV, G] -> [BC, G]\n   319\t        b_dp = tl.dot(b_v, tl.trans(b_do))\n   320\t        # [BC, G]\n   321\t        b_ds = b_p * (b_dp - b_delta[None, :])\n   322\t        # [BC, G] @ [G, BK] -> [BC, BK]\n   323\t        b_dk += tl.dot(b_ds.to(b_q.dtype), b_q)\n   324\t\n   325\t    tl.store(p_dk, b_dk.to(p_dk.dtype.element_ty), boundary_check=(0, 1))\n   326\t    tl.store(p_dv, b_dv.to(p_dv.dtype.element_ty), boundary_check=(0, 1))\n   327\t\n   328\t\n   329\t@triton.heuristics({\n   330\t    'USE_OFFSETS': lambda args: args['offsets'] is not None\n   331\t})\n   332\t@triton.autotune(\n   333\t    configs=[\n   334\t        triton.Config({}, num_warps=num_warps)\n   335\t        for num_warps in [1, 2, 4]\n   336\t    ],\n   337\t    key=['BS', 'BK'],\n   338\t)\n   339\t@triton.jit\n   340\tdef parallel_nsa_kernel_topk(\n   341\t    q,\n   342\t    k,\n   343\t    lse,\n   344\t    scale,\n   345\t    block_indices,\n   346\t    offsets,\n   347\t    token_indices,\n   348\t    chunk_offsets,\n   349\t    T,\n   350\t    H: tl.constexpr,\n   351\t    HQ: tl.constexpr,\n   352\t    G: tl.constexpr,\n   353\t    K: tl.constexpr,\n   354\t    S: tl.constexpr,\n   355\t    BC: tl.constexpr,\n   356\t    BS: tl.constexpr,\n   357\t    BK: tl.constexpr,\n   358\t    USE_OFFSETS: tl.constexpr,\n   359\t):\n   360\t    i_t, i_bh = tl.program_id(0), tl.program_id(1)\n   361\t    i_b, i_h = i_bh // H, i_bh % H\n   362\t\n   363\t    if USE_OFFSETS:\n   364\t        i_n, i_t = tl.load(token_indices + i_t * 2).to(tl.int32), tl.load(token_indices + i_t * 2 + 1).to(tl.int32)\n   365\t        bos, eos = tl.load(offsets + i_n).to(tl.int32), tl.load(offsets + i_n + 1).to(tl.int32)\n   366\t        T = eos - bos\n   367\t        boc = tl.load(chunk_offsets + i_n).to(tl.int32)\n   368\t    else:\n   369\t        bos, eos = i_b * T, i_b * T + T\n   370\t        boc = i_b * tl.cdiv(T, BS)\n   371\t\n   372\t    p_q = tl.make_block_ptr(q + (bos + i_t) * HQ*K, (HQ, K), (K, 1), (i_h * G, 0), (G, BK), (1, 0))\n   373\t\n   374\t    # the Q block is kept in the shared memory throughout the whole kernel\n   375\t    # [G, BK]\n   376\t    b_q = tl.load(p_q, boundary_check=(0, 1))\n   377\t    b_q = (b_q * scale).to(b_q.dtype)\n   378\t\n   379\t    # the number of compression representations in total\n   380\t    TC = tl.cdiv(T, BS)\n   381\t    # the number of compression representations required to iterate over\n   382\t    # incomplete compression blocks are not included\n   383\t    NC = (i_t + 1) // BS\n   384\t    ################################\n   385\t    # 1. lse computation\n   386\t    ################################\n   387\t    if lse is not None:\n   388\t        b_lse = tl.load(lse + (bos + i_t) * HQ + i_h * G + tl.arange(0, G))\n   389\t    else:\n   390\t        # max scores for the current block\n   391\t        b_m = tl.full([G], float('-inf'), dtype=tl.float32)\n   392\t        # lse = log(acc) + m\n   393\t        b_acc = tl.zeros([G], dtype=tl.float32)\n   394\t        for i_c in range(0, NC, BC):\n   395\t            o_c = i_c + tl.arange(0, BC)\n   396\t\n   397\t            p_k = tl.make_block_ptr(k + (boc * H + i_h) * K, (K, TC), (1, H*K), (0, i_c), (BK, BC), (0, 1))\n   398\t            # [BK, BC]\n   399\t            b_k = tl.load(p_k, boundary_check=(0, 1))\n   400\t\n   401\t            # [G, BC]\n   402\t            b_s = tl.dot(b_q, b_k)\n   403\t            b_s = tl.where((o_c < NC)[None, :], b_s, float('-inf'))\n   404\t\n   405\t            # [G]\n   406\t            b_m, b_mp = tl.maximum(b_m, tl.max(b_s, 1)), b_m\n   407\t            b_r = tl.exp(b_mp - b_m)\n   408\t            # [G, BC]\n   409\t            b_p = tl.exp(b_s - b_m[:, None])\n   410\t            # [G]\n   411\t            b_acc = b_acc * b_r + tl.sum(b_p, 1)\n   412\t\n   413\t            b_mp = b_m\n   414\t        if NC == 0:\n   415\t            b_lse = tl.zeros([G], dtype=tl.float32)\n   416\t        else:\n   417\t            b_lse = b_m + tl.log(b_acc)\n   418\t\n   419\t    ################################\n   420\t    # 2. topk selection\n   421\t    ################################\n   422\t    # [BC]\n   423\t    b_i = tl.full([BC], -1, dtype=tl.float32)\n   424\t    o_i = tl.zeros([BC], dtype=tl.int32)\n   425\t    m_i = tl.arange(0, BC) < BC//2\n   426\t    for i_c in range(0, i_t // BS + 1, BC):\n   427\t        o_c = i_c + tl.arange(0, BC)\n   428\t\n   429\t        p_k = tl.make_block_ptr(k + (boc * H + i_h) * K, (K, TC), (1, H*K), (0, i_c), (BK, BC), (0, 1))\n   430\t        # [BK, BC]\n   431\t        b_k = tl.load(p_k, boundary_check=(0, 1))\n   432\t        # [G, BC]\n   433\t        b_s = tl.dot(b_q, b_k)\n   434\t        b_s = tl.where((i_t // BS > o_c)[None, :], b_s, float('-inf'))\n   435\t        # [G, BC]\n   436\t        b_p = tl.where((i_t // BS == o_c)[None, :], float(1.0), tl.exp(b_s - b_lse[:, None]))\n   437\t        # the importance scores of the current block\n   438\t        # [BC]\n   439\t        b_i, b_ip = tl.sum(b_p, 0), b_i\n   440\t        o_i, o_ip = tl.where(o_c <= i_t // BS, o_c + 1, 0), o_i\n   441\t\n   442\t        n_dims: tl.constexpr = tl.standard._log2(b_i.shape[0])\n   443\t        for i in tl.static_range(1, n_dims):\n   444\t            b_i, o_i = _bitonic_merge(b_i, o_i.to(tl.int32), i, 2, n_dims)\n   445\t\n   446\t        if i_c != 0:\n   447\t            b_i, o_i = _bitonic_merge(b_i, o_i.to(tl.int32), n_dims, False, n_dims)\n   448\t            b_i_new = b_ip * m_i + b_i * (1 - m_i)\n   449\t            o_i_new = o_ip * m_i + o_i * (1 - m_i)\n   450\t            b_i, o_i = _bitonic_merge(b_i_new, o_i_new.to(tl.int32), n_dims, True, n_dims)\n   451\t        else:\n   452\t            b_i, o_i = _bitonic_merge(b_i, o_i.to(tl.int32), n_dims, True, n_dims)\n   453\t\n   454\t    m_top = tl.arange(0, BC//S) == 0\n   455\t    b_top = tl.sum(m_top[:, None] * tl.reshape(o_i - 1, [BC//S, S]), 0)\n   456\t\n   457\t    p_b = tl.make_block_ptr(block_indices + (bos + i_t) * H*S, (H*S,), (1,), (i_h * S,), (S,), (0,))\n   458\t    tl.store(p_b, b_top.to(p_b.dtype.element_ty))\n   459\t\n   460\t\n   461\t@triton.heuristics({\n   462\t    'USE_OFFSETS': lambda args: args['offsets'] is not None,\n   463\t    'USE_BLOCK_COUNTS': lambda args: isinstance(args['block_counts'], torch.Tensor),\n   464\t})\n   465\t@triton.autotune(\n   466\t    configs=[\n   467\t        triton.Config({}, num_warps=num_warps)\n   468\t        for num_warps in [1, 2, 4]\n   469\t    ],\n   470\t    key=['BS', 'BK', 'BV'],\n   471\t)\n   472\t@triton.jit\n   473\tdef parallel_nsa_fwd_kernel(\n   474\t    q,\n   475\t    k,\n   476\t    v,\n   477\t    o,\n   478\t    lse,\n   479\t    scale,\n   480\t    block_indices,\n   481\t    block_counts,\n   482\t    offsets,\n   483\t    token_indices,\n   484\t    T,\n   485\t    H: tl.constexpr,\n   486\t    HQ: tl.constexpr,\n   487\t    G: tl.constexpr,\n   488\t    K: tl.constexpr,\n   489\t    V: tl.constexpr,\n   490\t    S: tl.constexpr,\n   491\t    BS: tl.constexpr,\n   492\t    BK: tl.constexpr,\n   493\t    BV: tl.constexpr,\n   494\t    USE_OFFSETS: tl.constexpr,\n   495\t    USE_BLOCK_COUNTS: tl.constexpr\n   496\t):\n   497\t    i_t, i_v, i_bh = tl.program_id(0), tl.program_id(1), tl.program_id(2)\n   498\t    i_b, i_h = i_bh // H, i_bh % H\n   499\t\n   500\t    if USE_OFFSETS:\n   501\t        i_n, i_t = tl.load(token_indices + i_t * 2).to(tl.int32), tl.load(token_indices + i_t * 2 + 1).to(tl.int32)\n   502\t        bos, eos = tl.load(offsets + i_n).to(tl.int32), tl.load(offsets + i_n + <response clipped><NOTE>Due to the max output limit, only part of this file has been shown to you. You should retry this tool after you have searched inside the file with `grep -n` in order to find the line numbers of what you are looking for.</NOTE>\n", "extras": {"path": "/workspace/benchmark/datasets/19-Native-Sparse-Attention/NSA/native_sparse_attention/ops/parallel.py", "impl_source": "oh_aci"}}