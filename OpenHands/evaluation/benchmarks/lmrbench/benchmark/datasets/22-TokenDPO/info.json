{
    "instance_id": 22,
    "folder_name": "22-TokenDPO",
    "repo_folder_name": "TokenDPO-main",
    "paper_name": "Token-level Direct Preference Optimization",
    "paper_url": "https://arxiv.org/abs/2404.11999",
    "year": 2024,
    "repo_url": "https://github.com/Vance0124/Token-level-Direct-Preference-Optimization/tree/master",
    "implementations": [
        {
            "instruction": "Implement the `tdpo_loss` function in trainers.py based on the Token-level DPO loss mentioned in paper.pdf and the code repository. You may ignore the following parameters: if_tdpo2.",
            "index": 1,
            "category": "Training Objectives & Optimization Techniques",
            "goal_file": "trainers.py",
            "goal_function": "tdpo_loss",
            "class_name": "",
            "golden_file": "golden_files/trainers_golden.py",
            "retrieval_context": [],
            "unit_test_file": "unit_test/unit_test_1.py"
        }
    ]
}