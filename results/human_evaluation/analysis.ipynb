{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e50415d-20a3-4afc-9129-500d08e5e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# —— 1. 加载并合并原始 JSON 列表 ——\n",
    "with open('kaiyu.json', 'r', encoding='utf-8') as f:\n",
    "    kaiyu = json.load(f)\n",
    "with open('shuo.json', 'r', encoding='utf-8') as f:\n",
    "    shuo = json.load(f)\n",
    "with open('daoyang.json', 'r', encoding='utf-8') as f:\n",
    "    daoyang = json.load(f)\n",
    "with open('ziming.json', 'r', encoding='utf-8') as f:\n",
    "    ziming = json.load(f)\n",
    "\n",
    "# 对 ziming 中的 human_judge_result +1\n",
    "for rec in ziming:\n",
    "    rec['human_judge_result'] += 1\n",
    "\n",
    "# 合并所有记录，保持对原列表中 dict 的引用\n",
    "human_evaluation_data = kaiyu + shuo + daoyang + ziming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1acfc99-50cc-47df-b692-bed053e744c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n"
     ]
    }
   ],
   "source": [
    "print(len(human_evaluation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb368285-d029-47d9-a8f2-f5f9d0c14fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共有 28 条记录 human_judge_result=1 且 paper_index 在 [1, 2, 3, 7, 8, 9, 11, 30, 31] 中，需要处理。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# —— 2. 定义 outputs 基路径，往上一级目录 ———\n",
    "base_outputs = Path.cwd().parent / \"outputs\"\n",
    "\n",
    "\n",
    "# —— 3. 只保留 human_judge_result==1 且 paper_index 在指定列表中的记录 ——\n",
    "target_papers = [1, 2, 3, 7, 8, 9, 11, 30, 31]\n",
    "records_to_update = [\n",
    "    rec for rec in human_evaluation_data\n",
    "    if rec.get('human_judge_result') == 1 and rec.get('paper_index') in target_papers\n",
    "]\n",
    "print(f\"共有 {len(records_to_update)} 条记录 human_judge_result=1 且 paper_index 在 {target_papers} 中，需要处理。\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a32e0-a3b5-4875-8302-23a099bcaf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/28] 注释者=kaiyu, 代理=no_agent, 模型=gpt4.1, 论文=2, 函数索引=0\n",
      "Original comment: \"LLM using the other class function not used in gold answer, and the loss function didn't implement the forward, therefore the loss will return None\"\n",
      "\n",
      "Instruction:\n",
      "Implement the forward function of calulating the Hyperbolic Loss in src/hierarchy_transformers/losses/hit_loss.py based on paper.pdf.\n",
      "\n",
      "Goal Function: forward\n",
      "Class Name: HierarchyTransformerLoss\n",
      "\n",
      "--- src/hierarchy_transformers/losses/hit_loss.py 内容 ---\n",
      "from __future__ import annotations\n",
      "import logging\n",
      "from collections.abc import Iterable\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "from geoopt.manifolds import PoincareBall\n",
      "from hierarchy_transformers.models import HierarchyTransformer\n",
      "from hierarchy_transformers.utils import format_citation\n",
      "logger = logging.getLogger(__name__)\n",
      "\n",
      "class HierarchyTransformerLoss(torch.nn.Module):\n",
      "    \"\"\"Hyperbolic loss that linearly combines hperbolic clustering loss and hyperbolic Centripetal loss and applies weights for joint optimisation.\"\"\"\n",
      "\n",
      "    def __init__(self, model: HierarchyTransformer, clustering_loss_weight: float=1.0, clustering_loss_margin: float=5.0, centripetal_loss_weight: float=1.0, centripetal_loss_margin: float=0.5):\n",
      "        super().__init__()\n",
      "        self.model = model\n",
      "        self.manifold = self.model.manifold\n",
      "        self.cluster_weight = clustering_loss_weight\n",
      "        self.centri_weight = centripetal_loss_weight\n",
      "        self.cluster_loss_margin = clustering_loss_margin\n",
      "        self.centri_loss_margin = centripetal_loss_margin\n",
      "\n",
      "    def forward(self, sentence_features: Iterable[dict[str, torch.Tensor]], labels: torch.Tensor):\n",
      "        \"\"\"Forward propagation that follows [`sentence_transformers.losses`](https://github.com/UKPLab/sentence-transformers/tree/master/sentence_transformers/losses).\"\"\"\n",
      "        reps = [self.model(sentence_feature)['sentence_embedding'] for sentence_feature in sentence_features]\n",
      "        assert len(reps) == 3\n",
      "        rep_anchor, rep_positive, rep_negative = reps\n",
      "        cluster_loss_fn = HyperbolicClusteringLoss(self.manifold, self.cluster_loss_margin)\n",
      "        cluster_loss = cluster_loss_fn(rep_anchor, rep_positive, rep_negative)\n",
      "        centri_loss_fn = HyperbolicCentripetalLoss(self.manifold, self.centri_loss_margin)\n",
      "        centri_loss = centri_loss_fn(rep_anchor, rep_positive, rep_negative)\n",
      "        combined_loss = 0.0\n",
      "        if self.cluster_weight > 0.0 and cluster_loss is not None:\n",
      "            combined_loss = combined_loss + self.cluster_weight * cluster_loss\n",
      "        if self.centri_weight > 0.0 and centri_loss is not None:\n",
      "            combined_loss = combined_loss + self.centri_weight * centri_loss\n",
      "        return {'loss': combined_loss, 'cluster_loss': cluster_loss, 'centri_loss': centri_loss}\n",
      "\n",
      "    @property\n",
      "    def citation(self) -> str:\n",
      "        return format_citation('\\n            @article{he2024language,\\n              title={Language models as hierarchy encoders},\\n              author={He, Yuan and Yuan, Zhangdie and Chen, Jiaoyan and Horrocks, Ian},\\n              journal={arXiv preprint arXiv:2401.11374},\\n              year={2024}\\n            }\\n            ')\n",
      "\n",
      "class HyperbolicClusteringLoss(torch.nn.Module):\n",
      "    \"\"\"Hyperbolic loss that clusters entities in subsumptions.\n",
      "\n",
      "    Essentially, this loss is expected to achieve:\n",
      "\n",
      "    $$d(child, parent) < d(child, negative)$$\n",
      "\n",
      "    Inputs are presented in `(rep_anchor, rep_positive, rep_negative)`.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, manifold: PoincareBall, margin: float):\n",
      "        super().__init__()\n",
      "        self.manifold = manifold\n",
      "        self.margin = margin\n",
      "\n",
      "    def get_config_dict(self):\n",
      "        config = {'distance_metric': f'PoincareBall(c={self.manifold.c}).dist', 'margin': self.margin}\n",
      "        return config\n",
      "\n",
      "    def forward(self, rep_anchor: torch.Tensor, rep_positive: torch.Tensor, rep_negative: torch.Tensor):\n",
      "        pass\n",
      "\n",
      "    @property\n",
      "    def citation(self) -> str:\n",
      "        return format_citation('\\n            @article{he2024language,\\n              title={Language models as hierarchy encoders},\\n              author={He, Yuan and Yuan, Zhangdie and Chen, Jiaoyan and Horrocks, Ian},\\n              journal={arXiv preprint arXiv:2401.11374},\\n              year={2024}\\n            }\\n            ')\n",
      "\n",
      "class HyperbolicCentripetalLoss(torch.nn.Module):\n",
      "    \"\"\"Hyperbolic loss that regulates the norms of child and parent entities.\n",
      "\n",
      "    Essentially, this loss is expected to achieve:\n",
      "\n",
      "    $$d(child, origin) > d(parent, origin)$$\n",
      "\n",
      "    Inputs are presented in `(rep_anchor, rep_positive, rep_negative)` but only `(rep_anchor, rep_positive)` pairs are involved in this loss.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, manifold: PoincareBall, margin: float):\n",
      "        super().__init__()\n",
      "        self.manifold = manifold\n",
      "        self.margin = margin\n",
      "\n",
      "    def get_config_dict(self):\n",
      "        config = {'distance_metric': f'PoincareBall(c={self.manifold.c}).dist0', 'margin': self.margin}\n",
      "        return config\n",
      "\n",
      "    def forward(self, rep_anchor: torch.Tensor, rep_positive: torch.Tensor, rep_negative: torch.Tensor):\n",
      "        pass\n",
      "\n",
      "    @property\n",
      "    def citation(self) -> str:\n",
      "        return format_citation('\\n            @article{he2024language,\\n              title={Language models as hierarchy encoders},\\n              author={He, Yuan and Yuan, Zhangdie and Chen, Jiaoyan and Horrocks, Ian},\\n              journal={arXiv preprint arXiv:2401.11374},\\n              year={2024}\\n            }\\n            ')\n",
      "\n",
      "--- golden_files/hit_loss_golden.py 内容 ---\n",
      "# Copyright 2023 Yuan He\n",
      "\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\n",
      "\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "from __future__ import annotations\n",
      "\n",
      "import logging\n",
      "from collections.abc import Iterable\n",
      "\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "from geoopt.manifolds import PoincareBall\n",
      "\n",
      "from hierarchy_transformers.models import HierarchyTransformer\n",
      "from hierarchy_transformers.utils import format_citation\n",
      "\n",
      "logger = logging.getLogger(__name__)\n",
      "\n",
      "\n",
      "class HierarchyTransformerLoss(torch.nn.Module):\n",
      "    \"\"\"Hyperbolic loss that linearly combines hperbolic clustering loss and hyperbolic Centripetal loss and applies weights for joint optimisation.\"\"\"\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        model: HierarchyTransformer,\n",
      "        clustering_loss_weight: float = 1.0,\n",
      "        clustering_loss_margin: float = 5.0,\n",
      "        centripetal_loss_weight: float = 1.0,\n",
      "        centripetal_loss_margin: float = 0.5,\n",
      "    ):\n",
      "        super().__init__()\n",
      "\n",
      "        self.model = model\n",
      "        self.manifold = self.model.manifold\n",
      "        self.cluster_weight = clustering_loss_weight\n",
      "        self.centri_weight = centripetal_loss_weight\n",
      "        self.cluster_loss_margin = clustering_loss_margin\n",
      "        self.centri_loss_margin = centripetal_loss_margin\n",
      "\n",
      "    def forward(self, sentence_features: Iterable[dict[str, torch.Tensor]], labels: torch.Tensor):\n",
      "        \"\"\"Forward propagation that follows [`sentence_transformers.losses`](https://github.com/UKPLab/sentence-transformers/tree/master/sentence_transformers/losses).\"\"\"\n",
      "        reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "        assert len(reps) == 3\n",
      "        rep_anchor, rep_positive, rep_negative = reps\n",
      "\n",
      "        # compute and combine hyperbolic clustering and centripetal losses\n",
      "\n",
      "        # cluster_loss = self.cluster_loss(rep_anchor, rep_positive, rep_negative)\n",
      "        distances_positive = self.manifold.dist(rep_anchor, rep_positive)\n",
      "        distances_negative = self.manifold.dist(rep_anchor, rep_negative)\n",
      "        cluster_triplet_loss = F.relu(distances_positive - distances_negative + self.cluster_loss_margin)\n",
      "        cluster_loss = cluster_triplet_loss.mean()\n",
      "\n",
      "        # centri_loss = self.centri_loss(rep_anchor, rep_positive, rep_negative)\n",
      "        rep_anchor_hyper_norms = self.manifold.dist0(rep_anchor)\n",
      "        rep_positive_hyper_norms = self.manifold.dist0(rep_positive)\n",
      "        # child further than parent w.r.t. origin\n",
      "        centri_triplet_loss = F.relu(self.centri_loss_margin + rep_positive_hyper_norms - rep_anchor_hyper_norms)\n",
      "        centri_loss = centri_triplet_loss.mean()\n",
      "\n",
      "        combined_loss = self.cluster_weight * cluster_loss + self.centri_weight * centri_loss\n",
      "\n",
      "        return {\n",
      "            \"loss\": combined_loss,\n",
      "            \"cluster_loss\": cluster_loss,\n",
      "            \"centri_loss\": centri_loss,\n",
      "        }\n",
      "\n",
      "    @property\n",
      "    def citation(self) -> str:\n",
      "        return format_citation(\n",
      "            \"\"\"\n",
      "            @article{he2024language,\n",
      "              title={Language models as hierarchy encoders},\n",
      "              author={He, Yuan and Yuan, Zhangdie and Chen, Jiaoyan and Horrocks, Ian},\n",
      "              journal={arXiv preprint arXiv:2401.11374},\n",
      "              year={2024}\n",
      "            }\n",
      "            \"\"\"\n",
      "        )\n",
      "\n",
      "\n",
      "class HyperbolicClusteringLoss(torch.nn.Module):\n",
      "    r\"\"\"Hyperbolic loss that clusters entities in subsumptions.\n",
      "\n",
      "    Essentially, this loss is expected to achieve:\n",
      "\n",
      "    $$d(child, parent) < d(child, negative)$$\n",
      "\n",
      "    Inputs are presented in `(rep_anchor, rep_positive, rep_negative)`.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, manifold: PoincareBall, margin: float):\n",
      "        super().__init__()\n",
      "        self.manifold = manifold\n",
      "        self.margin = margin\n",
      "\n",
      "    def get_config_dict(self):\n",
      "        config = {\n",
      "            \"distance_metric\": f\"PoincareBall(c={self.manifold.c}).dist\",\n",
      "            \"margin\": self.margin,\n",
      "        }\n",
      "        return config\n",
      "\n",
      "    def forward(self, rep_anchor: torch.Tensor, rep_positive: torch.Tensor, rep_negative: torch.Tensor):\n",
      "        pass\n",
      "\n",
      "    @property\n",
      "    def citation(self) -> str:\n",
      "        return format_citation(\n",
      "            \"\"\"\n",
      "            @article{he2024language,\n",
      "              title={Language models as hierarchy encoders},\n",
      "              author={He, Yuan and Yuan, Zhangdie and Chen, Jiaoyan and Horrocks, Ian},\n",
      "              journal={arXiv preprint arXiv:2401.11374},\n",
      "              year={2024}\n",
      "            }\n",
      "            \"\"\"\n",
      "        )\n",
      "\n",
      "\n",
      "class HyperbolicCentripetalLoss(torch.nn.Module):\n",
      "    r\"\"\"Hyperbolic loss that regulates the norms of child and parent entities.\n",
      "\n",
      "    Essentially, this loss is expected to achieve:\n",
      "\n",
      "    $$d(child, origin) > d(parent, origin)$$\n",
      "\n",
      "    Inputs are presented in `(rep_anchor, rep_positive, rep_negative)` but only `(rep_anchor, rep_positive)` pairs are involved in this loss.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, manifold: PoincareBall, margin: float):\n",
      "        super().__init__()\n",
      "        self.manifold = manifold\n",
      "        self.margin = margin\n",
      "\n",
      "    def get_config_dict(self):\n",
      "        config = {\n",
      "            \"distance_metric\": f\"PoincareBall(c={self.manifold.c}).dist0\",\n",
      "            \"margin\": self.margin,\n",
      "        }\n",
      "        return config\n",
      "\n",
      "    def forward(self, rep_anchor: torch.Tensor, rep_positive: torch.Tensor, rep_negative: torch.Tensor):\n",
      "        pass\n",
      " \n",
      "    @property\n",
      "    def citation(self) -> str:\n",
      "        return format_citation(\n",
      "            \"\"\"\n",
      "            @article{he2024language,\n",
      "              title={Language models as hierarchy encoders},\n",
      "              author={He, Yuan and Yuan, Zhangdie and Chen, Jiaoyan and Horrocks, Ian},\n",
      "              journal={arXiv preprint arXiv:2401.11374},\n",
      "              year={2024}\n",
      "            }\n",
      "            \"\"\"\n",
      "        )\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, record in enumerate(records_to_update, 1):\n",
    "    annotator     = record['annotator']\n",
    "    agent_type    = record['agent_type']\n",
    "    model_name    = record['model_name']\n",
    "    paper_index   = record['paper_index']\n",
    "    function_index= record['function_index']\n",
    "    original_comment = record.get('comment', '')\n",
    "    \n",
    "    # 选择 BaseAgent 或 OpenHands 目录\n",
    "    agent_dir = \"BaseAgent\" if agent_type == \"no_agent\" else \"OpenHands\"\n",
    "    model_dir = base_outputs / agent_dir / model_name\n",
    "    \n",
    "    # 查找以 \"{paper_index}-\" 开头的论文文件夹\n",
    "    paper_folders = [p for p in model_dir.iterdir() \n",
    "                     if p.is_dir() and p.name.startswith(f\"{paper_index}-\")]\n",
    "    if not paper_folders:\n",
    "        print(f\"❌ 未找到论文 {paper_index} 文件夹: {model_dir}\")\n",
    "        continue\n",
    "    paper_folder = sorted(paper_folders)[0]\n",
    "    \n",
    "    # 读取 info.json\n",
    "    info = json.loads((paper_folder / \"info.json\").read_text(encoding='utf-8'))\n",
    "    repo_folder_name = info['repo_folder_name']\n",
    "    impls = info['implementations']\n",
    "    \n",
    "    # 获取指定实现项\n",
    "    impl = impls[function_index]\n",
    "    instruction    = impl.get('instruction', '')\n",
    "    goal_file_rel  = impl.get('goal_file', '')\n",
    "    goal_function  = impl.get('goal_function', '')\n",
    "    class_name     = impl.get('class_name', '')\n",
    "    golden_file_rel= impl.get('golden_file', '')\n",
    "    \n",
    "    # —— 打印元信息和文件内容 ——\n",
    "    print(f\"\\n[{idx}/{len(records_to_update)}] 注释者={annotator}, 代理={agent_type}, 模型={model_name}, \"\n",
    "          f\"论文={paper_index}, 函数索引={function_index}\")\n",
    "    print(f\"Original comment: {original_comment!r}\\n\")\n",
    "\n",
    "    print(f\"Instruction:\\n{instruction}\\n\")\n",
    "    print(f\"Goal Function: {goal_function}\")\n",
    "    print(f\"Class Name: {class_name}\\n\")\n",
    "    \n",
    "    # goal_file\n",
    "    goal_path = paper_folder / repo_folder_name / goal_file_rel\n",
    "    if goal_path.exists():\n",
    "        print(f\"--- {goal_file_rel} 内容 ---\")\n",
    "        print(goal_path.read_text(encoding='utf-8'))\n",
    "    else:\n",
    "        print(f\"❌ 未找到 goal_file: {goal_path}\")\n",
    "    \n",
    "    # golden_file\n",
    "    golden_path = paper_folder / golden_file_rel\n",
    "    if golden_path.exists():\n",
    "        print(f\"\\n--- {golden_file_rel} 内容 ---\")\n",
    "        print(golden_path.read_text(encoding='utf-8'))\n",
    "    else:\n",
    "        print(f\"❌ 未找到 golden_file: {golden_path}\")\n",
    "    \n",
    "    # —— 交互式输入 comment —— \n",
    "    new_comment = input(\"\\n请输入新的 comment（留空跳过）：\").strip()\n",
    "    if new_comment:\n",
    "        record['comment'] = new_comment\n",
    "        print(\"✅ 已更新 comment。\\n\")\n",
    "    else:\n",
    "        print(\"⏭️ 跳过，不修改 comment。\\n\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a2e76e-5664-4adc-b0e5-841b9ba4510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_map = {\n",
    "    'kaiyu': kaiyu,\n",
    "    'shuo': shuo,\n",
    "    'daoyang': daoyang,\n",
    "    'ziming': ziming,\n",
    "}\n",
    "for filename, data_list in file_map.items():\n",
    "    with open(f'{filename}.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(data_list, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"💾 保存更新到 {filename}.json\")\n",
    "\n",
    "print(\"\\n全部处理完毕。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
